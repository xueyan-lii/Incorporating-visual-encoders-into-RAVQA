/home/xl544/.conda/envs/BLIP2/lib/python3.8/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: libtorch_cuda_cu.so: cannot open shared object file: No such file or directory
  warn(f"Failed to load image Python extension: {e}")
/home/xl544/.conda/envs/BLIP2/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning
  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')
[38;20m[INFO] - __main__ : Initialization done with the config: {'DATA_FOLDER': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Data', 'EXPERIMENT_FOLDER': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments', 'TENSORBOARD_FOLDER': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Data_TB/tb_logs', 'WANDB': {'entity': 'xl544', 'project': 'RAVQA', 'tags': ['OKVQA', 'T5'], 'name': 'OKVQA_NoDPR-flanT5-qf.22963435'}, 'cache': {'default_folder': '../data/ok-vqa/cache', 'regenerate': {'clip_embeddings': 0, 'ocr_feature_preprocessed': 0, 'qformer_embeddings': 0, 'test_data_preprocessed': 0, 'train_data_preprocessed': 0, 'vinvl_feature_preprocessed': 0}}, 'cuda': 0, 'data_loader': {'additional': {'max_decoder_source_length': 512, 'max_source_length': 512, 'max_target_length': 10}, 'dataset_modules': {'module_dict': {'LoadClipEmbeddings': {'config': {'clip_embeddings': {'train': '../data/ok-vqa/pre-extracted_features/clip_embeddings/coco_ViT-L_14@336px_train2014.pkl', 'val': '../data/ok-vqa/pre-extracted_features/clip_embeddings/coco_ViT-L_14@336px_val2014.pkl'}, 'qformer_embeddings': {'train': '../data/ok-vqa/pre-extracted_features/blip2_head_embeddings/coco_hgface_qformer_train2014.pkl', 'val': '../data/ok-vqa/pre-extracted_features/blip2_head_embeddings/coco_hgface_qformer_val2014.pkl'}, 'raw_pixels': {'train': '../data/ok-vqa/pre-extracted_features/raw-pixels/okvqa_raw_pixels_train2014.pkl', 'val': '../data/ok-vqa/pre-extracted_features/raw-pixels/okvqa_raw_pixels_val2014.pkl'}}, 'option': 'default', 'type': 'EmbeddingInput'}, 'LoadGoogleOCRFeatures': {'config': {'combine_with_vinvl': True, 'test': '../data/ok-vqa/pre-extracted_features/OCR/valid', 'train': '../data/ok-vqa/pre-extracted_features/OCR/train'}, 'option': 'default', 'type': 'LoadGoogleOCRFeatures'}, 'LoadGoogleSearchAnnotations': {'config': {'annotations_path': {'test': '../data/ok-vqa/pre-extracted_features/passages/retriever_test.json', 'train': '../data/ok-vqa/pre-extracted_features/passages/retriever_train.json', 'valid': '../data/ok-vqa/pre-extracted_features/passages/retriever_testdev.json'}}, 'option': 'default', 'type': 'LoadGoogleSearchAnnotations'}, 'LoadGoogleSearchPassageData': {'config': {'passage_data_path': {'full': '../data/ok-vqa/pre-extracted_features/passages/okvqa_full_corpus.csv', 'train': '../data/ok-vqa/pre-extracted_features/passages/okvqa_train_corpus.csv'}, 'use_full_split': True}, 'option': 'default', 'type': 'LoadGoogleSearchPassageData'}, 'LoadOKVQAData': {'config': {'image_data_path': {'test': '../data/ok-vqa/val2014', 'train': '../data/ok-vqa/train2014'}, 'vqa_data_path': {'annotation_files': {'test': '../data/ok-vqa/mscoco_val2014_annotations.json', 'train': '../data/ok-vqa/mscoco_train2014_annotations.json'}, 'question_files': {'test': '../data/ok-vqa/OpenEnded_mscoco_val2014_questions.json', 'train': '../data/ok-vqa/OpenEnded_mscoco_train2014_questions.json'}}}, 'option': 'default', 'type': 'LoadOKVQAData'}, 'LoadOscarCaptionFeatures': {'config': {'test': '../data/ok-vqa/pre-extracted_features/captions/test_predictions.json', 'train': '../data/ok-vqa/pre-extracted_features/captions/train_predictions.json', 'valid': '../data/ok-vqa/pre-extracted_features/captions/valid_predictions.json'}, 'option': 'default', 'type': 'LoadOscarCaptionFeatures'}, 'LoadPretrainedDPROutputForGoogleSearchPassage': {'config': {'pretrained_dpr_outputs': {'test': '../Experiments/Knowledge_Retriever_DPR_dim_768_inbatch_negative_caption_FullCorpus_NewRun/test/test_evaluation/test_predictions.json', 'train': '../Experiments/Knowledge_Retriever_DPR_dim_768_inbatch_negative_caption_FullCorpus_NewRun/test/test_evaluation/train_predictions.json'}}, 'option': 'none', 'type': 'LoadPretrainedDPROutputForGoogleSearchPassage'}, 'LoadVinVLFeatures': {'config': {'test': '../data/ok-vqa/pre-extracted_features/vinvl_output/vinvl_okvqa_testset_full/inference/vinvl_vg_x152c4/predictions.tsv', 'train': '../data/ok-vqa/pre-extracted_features/vinvl_output/vinvl_okvqa_trainset_full/inference/vinvl_vg_x152c4/predictions.tsv'}, 'option': 'default', 'type': 'LoadVinVLFeatures'}}, 'module_list': ['LoadVinVLFeatures', 'LoadGoogleOCRFeatures', 'LoadOscarCaptionFeatures', 'LoadOKVQAData', 'LoadClipEmbeddings']}, 'dataset_type': 'OKVQADataset', 'dummy_dataloader': 0, 'type': 'DataLoaderOKVQA'}, 'experiment_name': 'OKVQA_NoDPR-flanT5-qf.22963435', 'gpu_device': 0, 'ignore_pretrained_weights': [], 'metrics': [{'name': 'compute_okvqa_scores'}], 'model_config': {'ConfigClass': 'T5Config', 'GeneratorModelClass': 'T5ForConditionalGeneration', 'LoadPretrainMLP': 0, 'ModelClass': 'PrefixModel', 'ModelVersion': 'google/flan-t5-large', 'SPECIAL_TOKENS': {'additional_special_tokens': ['<BOQ>', '<EOQ>'], 'bos_token': '<PAD>', 'pad_token': '<PAD>'}, 'TokenizerClass': 'T5Tokenizer', 'TokenizerModelVersion': 'google/flan-t5-large', 'UsePrefixEmb': 0.5, 'UseQformerEmb': 1, 'UseRawPixels': 0, 'base_model': 'T5', 'decoder_input_modules': {'module_list': [], 'postprocess_module_list': []}, 'input_modules': {'module_list': [{'option': 'default', 'separation_tokens': {'end': '<EOQ>', 'start': '<BOQ>'}, 'type': 'QuestionInput'}, {'option': 'default', 'type': 'EmbeddingInput'}], 'postprocess_module_list': [{'option': 'default', 'type': 'PostProcessInputTokenization'}, {'option': 'default', 'type': 'PostProcessClipEmbeddings'}]}, 'loss_ratio': {'additional_loss': 0, 'nll_loss': 1, 'rag_loss': 0}, 'modules': [], 'output_modules': {'module_list': [{'option': 'default', 'type': 'GenerationOutput'}], 'postprocess_module_list': [{'option': 'default', 'type': 'PostProcessOutputTokenization'}]}, 'pretrained': 1, 'rag_modules': {'module_list': []}, 'LoadPretrainedMLP': 0}, 'platform_type': 'pytorch', 'seed': 2021, 'test': {'additional': {'multiprocessing': 4}, 'batch_size': 32, 'evaluation_name': 'test_evaluation', 'load_best_model': 0, 'load_epoch': -1, 'load_model_path': '', 'num_evaluation': 0}, 'train': {'MLP_lr': 0.0001, 'adam_epsilon': 1e-08, 'additional': {'gradient_accumulation_steps': 16, 'gradient_clipping': 0, 'plugins': [], 'save_top_k': 1, 'save_top_k_metric': 'test/accuracy_overall', 'save_top_k_mode': 'max', 'warmup_steps': 0}, 'batch_size': 2, 'epochs': 20, 'load_best_model': 0, 'load_epoch': -1, 'load_model_path': '/home/xl544/rds/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22960559/train/saved_model/model_9.ckpt', 'lr': 6e-05, 'retriever_lr': 1e-05, 'save_interval': 1, 'scheduler': 'linear', 'type': 'T5ExecutorWithPrefix'}, 'valid': {'additional': {}, 'batch_size': 32, 'break_interval': 3000, 'step_size': 0.5}, 'reset': False, 'mode': 'train', 'log_path': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435/train', 'experiment_path': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435', 'saved_model_path': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435/train/saved_model', 'imgs_path': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435/train/imgs', 'tensorboard_path': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Data_TB/tb_logs/OKVQA_NoDPR-flanT5-qf.22963435', 'args': {'config': '../configs/okvqa/T5_NoDPR_prefix_only.jsonnet', 'DATA_FOLDER': '', 'EXPERIMENT_FOLDER': '', 'mode': 'train', 'reset': False, 'experiment_name': 'OKVQA_NoDPR-flanT5-qf.22963435', 'tags': [], 'modules': [], 'log_prediction_tables': False, 'test_batch_size': -1, 'test_evaluation_name': '', 'logger': True, 'checkpoint_callback': None, 'enable_checkpointing': True, 'default_root_dir': None, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'process_position': 0, 'num_nodes': 1, 'num_processes': None, 'devices': '1', 'gpus': None, 'auto_select_gpus': False, 'tpu_cores': None, 'ipus': None, 'log_gpu_memory': None, 'progress_bar_refresh_rate': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 1, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': None, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'flush_logs_every_n_steps': None, 'log_every_n_steps': 50, 'accelerator': 'auto', 'strategy': None, 'sync_batchnorm': False, 'precision': 32, 'enable_model_summary': True, 'weights_summary': 'top', 'weights_save_path': None, 'num_sanity_val_steps': 2, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'deterministic': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': True, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'prepare_data_per_node': None, 'plugins': None, 'amp_backend': 'native', 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'stochastic_weight_avg': False, 'terminate_on_nan': None, 'opts': ['train.epochs=20', 'train.batch_size=2', 'valid.step_size=0.5', 'valid.batch_size=32', 'train.additional.gradient_accumulation_steps=16', 'train.lr=0.00006', 'train.MLP_lr=0.0001', 'train.scheduler=linear', 'train.load_model_path=/home/xl544/rds/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22960559/train/saved_model/model_9.ckpt', 'model_config.UsePrefixEmb=0.5', 'model_config.UseQformerEmb=1', 'model_config.LoadPretrainedMLP=0', 'model_config.TokenizerModelVersion=google/flan-t5-large', 'model_config.ModelVersion=google/flan-t5-large']}}[0m
Global seed set to 2021
[38;20m[INFO] - __main__ : All seeds have been set to 2021[0m
[38;20m[INFO] - __main__ : init wandb logger with the following settings: {'entity': 'xl544', 'project': 'RAVQA', 'tags': ['OKVQA', 'T5'], 'name': 'OKVQA_NoDPR-flanT5-qf.22963435'}[0m
wandb: Currently logged in as: xl544. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.15.4
wandb: Run data is saved locally in /rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/src/wandb/run-20230625_161939-6ka148e2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run OKVQA_NoDPR-flanT5-qf.22963435
wandb: ⭐️ View project at https://wandb.ai/xl544/RAVQA
wandb: 🚀 View run at https://wandb.ai/xl544/RAVQA/runs/6ka148e2
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[38;20m[INFO] - __main__ : arguments passed to trainer: Namespace(DATA_FOLDER='', EXPERIMENT_FOLDER='', accelerator='auto', accumulate_grad_batches=None, amp_backend='native', amp_level=None, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, benchmark=None, check_val_every_n_epoch=1, checkpoint_callback=None, config='../configs/okvqa/T5_NoDPR_prefix_only.jsonnet', default_root_dir=None, detect_anomaly=False, deterministic=None, devices='1', enable_checkpointing=True, enable_model_summary=True, enable_progress_bar=True, experiment_name='OKVQA_NoDPR-flanT5-qf.22963435', fast_dev_run=False, flush_logs_every_n_steps=None, gpus=None, gradient_clip_algorithm=None, gradient_clip_val=None, ipus=None, limit_predict_batches=None, limit_test_batches=None, limit_train_batches=None, limit_val_batches=None, log_every_n_steps=50, log_gpu_memory=None, log_prediction_tables=False, logger=True, max_epochs=None, max_steps=-1, max_time=None, min_epochs=None, min_steps=None, mode='train', modules=[], move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=None, num_sanity_val_steps=2, opts=['train.epochs=20', 'train.batch_size=2', 'valid.step_size=0.5', 'valid.batch_size=32', 'train.additional.gradient_accumulation_steps=16', 'train.lr=0.00006', 'train.MLP_lr=0.0001', 'train.scheduler=linear', 'train.load_model_path=/home/xl544/rds/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22960559/train/saved_model/model_9.ckpt', 'model_config.UsePrefixEmb=0.5', 'model_config.UseQformerEmb=1', 'model_config.LoadPretrainedMLP=0', 'model_config.TokenizerModelVersion=google/flan-t5-large', 'model_config.ModelVersion=google/flan-t5-large'], overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=None, process_position=0, profiler=None, progress_bar_refresh_rate=None, reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, reset=False, resume_from_checkpoint=None, stochastic_weight_avg=False, strategy=None, sync_batchnorm=False, tags=[], terminate_on_nan=None, test_batch_size=-1, test_evaluation_name='', tpu_cores=None, track_grad_norm=-1, val_check_interval=None, weights_save_path=None, weights_summary='top')[0m
[38;20m[INFO] - __main__ : additional arguments passed to trainer: {'accumulate_grad_batches': 16, 'default_root_dir': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435/train/saved_model', 'max_epochs': 20, 'logger': [<pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x147bc0ddfdf0>, <pytorch_lightning.loggers.wandb.WandbLogger object at 0x147bc0ddfeb0>, <utils.metrics_log_callback.MetricsHistoryLogger object at 0x147bc067fca0>], 'callbacks': [<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x147bc0dee610>, <pytorch_lightning.callbacks.progress.tqdm_progress.TQDMProgressBar object at 0x147bc0428880>, <pytorch_lightning.callbacks.model_summary.ModelSummary object at 0x147bc04287c0>, <pytorch_lightning.callbacks.gradient_accumulation_scheduler.GradientAccumulationScheduler object at 0x147bc0428760>], 'plugins': [], 'log_every_n_steps': 10, 'val_check_interval': 0.5}[0m
[38;20m[INFO] - data_loader_manager.data_loader_wrapper : Loading dataset module: {'config': {'test': '../data/ok-vqa/pre-extracted_features/vinvl_output/vinvl_okvqa_testset_full/inference/vinvl_vg_x152c4/predictions.tsv', 'train': '../data/ok-vqa/pre-extracted_features/vinvl_output/vinvl_okvqa_trainset_full/inference/vinvl_vg_x152c4/predictions.tsv'}, 'option': 'default', 'type': 'LoadVinVLFeatures'}[0m
[38;20m[INFO] - utils.cache_system : reading preprocessed data from ../data/ok-vqa/cache/vinvl_feature_preprocessed.pkl[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : [Data Statistics] VinVL features 14031[0m
[38;20m[INFO] - data_loader_manager.data_loader_wrapper : Loading dataset module: {'config': {'combine_with_vinvl': True, 'test': '../data/ok-vqa/pre-extracted_features/OCR/valid', 'train': '../data/ok-vqa/pre-extracted_features/OCR/train'}, 'option': 'default', 'type': 'LoadGoogleOCRFeatures'}[0m
[38;20m[INFO] - utils.cache_system : reading preprocessed data from ../data/ok-vqa/cache/ocr_feature_preprocessed.pkl[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : [Data Statistics] OCR features 14031, 5462 has annotations.[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : OCR feature detected in VinVL feature dict...skipping..[0m
[38;20m[INFO] - data_loader_manager.data_loader_wrapper : Loading dataset module: {'config': {'test': '../data/ok-vqa/pre-extracted_features/captions/test_predictions.json', 'train': '../data/ok-vqa/pre-extracted_features/captions/train_predictions.json', 'valid': '../data/ok-vqa/pre-extracted_features/captions/valid_predictions.json'}, 'option': 'default', 'type': 'LoadOscarCaptionFeatures'}[0m
[38;20m[INFO] - data_loader_manager.data_loader_wrapper : Loading dataset module: {'config': {'image_data_path': {'test': '../data/ok-vqa/val2014', 'train': '../data/ok-vqa/train2014'}, 'vqa_data_path': {'annotation_files': {'test': '../data/ok-vqa/mscoco_val2014_annotations.json', 'train': '../data/ok-vqa/mscoco_train2014_annotations.json'}, 'question_files': {'test': '../data/ok-vqa/OpenEnded_mscoco_val2014_questions.json', 'train': '../data/ok-vqa/OpenEnded_mscoco_train2014_questions.json'}}}, 'option': 'default', 'type': 'LoadOKVQAData'}[0m
[38;20m[INFO] - utils.cache_system : reading preprocessed data from ../data/ok-vqa/cache/train_data_preprocessed.pkl[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : [Data statistics] split: train  entries: 9009[0m
[38;20m[INFO] - utils.cache_system : reading preprocessed data from ../data/ok-vqa/cache/test_data_preprocessed.pkl[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : [Data statistics] split: test  entries: 5046[0m
[38;20m[INFO] - data_loader_manager.data_loader_wrapper : Loading dataset module: {'config': {'clip_embeddings': {'train': '../data/ok-vqa/pre-extracted_features/clip_embeddings/coco_ViT-L_14@336px_train2014.pkl', 'val': '../data/ok-vqa/pre-extracted_features/clip_embeddings/coco_ViT-L_14@336px_val2014.pkl'}, 'qformer_embeddings': {'train': '../data/ok-vqa/pre-extracted_features/blip2_head_embeddings/coco_hgface_qformer_train2014.pkl', 'val': '../data/ok-vqa/pre-extracted_features/blip2_head_embeddings/coco_hgface_qformer_val2014.pkl'}, 'raw_pixels': {'train': '../data/ok-vqa/pre-extracted_features/raw-pixels/okvqa_raw_pixels_train2014.pkl', 'val': '../data/ok-vqa/pre-extracted_features/raw-pixels/okvqa_raw_pixels_val2014.pkl'}}, 'option': 'default', 'type': 'EmbeddingInput'}[0m
[38;20m[INFO] - utils.cache_system : reading preprocessed data from ../data/ok-vqa/cache/qformer_embeddings.pkl[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : [Data Statistics] CLIP embeddings 14031[0m
[38;20m[INFO] - data_loader_manager.datasets.okvqa_datasets : initialising OKVQADataset...[0m
[38;20m[INFO] - data_loader_manager.datasets.okvqa_datasets : initialising OKVQADataset...[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : [Data Statistics]: training data loader: 4505;  test data loader: 158[0m
[38;20m[INFO] - torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpetrv15b9[0m
[38;20m[INFO] - torch.distributed.nn.jit.instantiator : Writing /tmp/tmpetrv15b9/_remote_module_non_scriptable.py[0m
[38;20m[INFO] - trainers.base_executor : Initializing T5ExecutorWithPrefix...[0m
[38;20m[INFO] - __main__ : config file was successfully saved to /rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435 for future use.[0m
Restoring states from the checkpoint path at /home/xl544/rds/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22960559/train/saved_model/model_9.ckpt
/home/xl544/.conda/envs/BLIP2/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:342: UserWarning: The dirpath has changed from '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22960559/train/saved_model' to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435/train/saved_model', therefore `best_model_score`, `kth_best_model_path`, `kth_value`, `last_model_path` and `best_k_models` won't be reloaded. Only `best_model_path` will be reloaded.
  warnings.warn(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[38;20m[INFO] - trainers.t5_executor_with_prefix : #params: 558   lr: 6e-05[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : #params: 2   lr: 0.0001[0m
Loading `train_dataloader` to estimate number of stepping batches.
/home/xl544/.conda/envs/BLIP2/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

  | Name  | Type        | Params
--------------------------------------
0 | model | PrefixModel | 783 M 
--------------------------------------
783 M     Trainable params
0         Non-trainable params
783 M     Total params
3,135.545 Total estimated model params size (MB)
Missing logger folder: /rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Data_TB/tb_logs/OKVQA_NoDPR-flanT5-qf.22963435/OKVQA_NoDPR-flanT5-qf.22963435
Restored all states from the checkpoint file at /home/xl544/rds/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22960559/train/saved_model/model_9.ckpt
SLURM auto-requeueing enabled. Setting signal handlers.
/home/xl544/.conda/envs/BLIP2/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/src/data_loader_manager/module_parser.py:301: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  clip_embeddings=torch.stack([torch.tensor(clip_embedding) for clip_embedding in sample.clip_embedding]),
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Failed to compute OKVQA scores: Results do not correspond to current VQA set. Either the results do not have predictions for all question ids in annotation file or there is atleast one question id that does not belong to the question ids in the annotation file.This could be due to the fact that OKVQA parser requires all questions to evaluatethe accuracy. Ignore this error if this is the sanity check.[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [sanity_check]: {'test/epoch': 9}[0m
[33;20m[WARNING] - root : Sanity check mode, not saving to loggers.[0m
/home/xl544/.conda/envs/BLIP2/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 33.63, 'test/accuracy_QuestionType_one': 31.0, 'test/accuracy_QuestionType_eight': 32.7, 'test/accuracy_QuestionType_other': 34.64, 'test/accuracy_QuestionType_seven': 32.01, 'test/accuracy_QuestionType_four': 44.66, 'test/accuracy_QuestionType_five': 31.75, 'test/accuracy_QuestionType_three': 32.38, 'test/accuracy_QuestionType_nine': 26.9, 'test/accuracy_QuestionType_ten': 41.71, 'test/accuracy_QuestionType_two': 29.65, 'test/accuracy_QuestionType_six': 26.81, 'test/accuracy_AnswerType_other': 33.63, 'test/epoch': 10}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 33.0, 'test/accuracy_QuestionType_one': 29.91, 'test/accuracy_QuestionType_eight': 29.44, 'test/accuracy_QuestionType_other': 35.28, 'test/accuracy_QuestionType_seven': 31.36, 'test/accuracy_QuestionType_four': 44.87, 'test/accuracy_QuestionType_five': 31.9, 'test/accuracy_QuestionType_three': 32.94, 'test/accuracy_QuestionType_nine': 27.62, 'test/accuracy_QuestionType_ten': 42.17, 'test/accuracy_QuestionType_two': 27.79, 'test/accuracy_QuestionType_six': 27.52, 'test/accuracy_AnswerType_other': 33.0, 'test/epoch': 10}[0m
/home/xl544/.conda/envs/BLIP2/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 10, global step 3102: 'test/accuracy_overall' reached 33.00000 (best 33.00000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435/train/saved_model/model_10.ckpt' as top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 33.89, 'test/accuracy_QuestionType_one': 29.72, 'test/accuracy_QuestionType_eight': 33.28, 'test/accuracy_QuestionType_other': 34.96, 'test/accuracy_QuestionType_seven': 33.93, 'test/accuracy_QuestionType_four': 43.7, 'test/accuracy_QuestionType_five': 32.62, 'test/accuracy_QuestionType_three': 33.6, 'test/accuracy_QuestionType_nine': 29.29, 'test/accuracy_QuestionType_ten': 41.4, 'test/accuracy_QuestionType_two': 29.07, 'test/accuracy_QuestionType_six': 27.23, 'test/accuracy_AnswerType_other': 33.89, 'test/epoch': 11}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 33.71, 'test/accuracy_QuestionType_one': 30.09, 'test/accuracy_QuestionType_eight': 33.14, 'test/accuracy_QuestionType_other': 34.7, 'test/accuracy_QuestionType_seven': 32.52, 'test/accuracy_QuestionType_four': 42.72, 'test/accuracy_QuestionType_five': 32.25, 'test/accuracy_QuestionType_three': 34.07, 'test/accuracy_QuestionType_nine': 29.29, 'test/accuracy_QuestionType_ten': 41.09, 'test/accuracy_QuestionType_two': 29.53, 'test/accuracy_QuestionType_six': 29.22, 'test/accuracy_AnswerType_other': 33.71, 'test/epoch': 11}[0m
Epoch 11, global step 3384: 'test/accuracy_overall' reached 33.71000 (best 33.71000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435/train/saved_model/model_11.ckpt' as top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 32.92, 'test/accuracy_QuestionType_one': 28.61, 'test/accuracy_QuestionType_eight': 31.58, 'test/accuracy_QuestionType_other': 33.28, 'test/accuracy_QuestionType_seven': 31.54, 'test/accuracy_QuestionType_four': 42.01, 'test/accuracy_QuestionType_five': 33.22, 'test/accuracy_QuestionType_three': 32.43, 'test/accuracy_QuestionType_nine': 29.52, 'test/accuracy_QuestionType_ten': 38.29, 'test/accuracy_QuestionType_two': 31.16, 'test/accuracy_QuestionType_six': 31.06, 'test/accuracy_AnswerType_other': 32.92, 'test/epoch': 12}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 33.86, 'test/accuracy_QuestionType_one': 29.86, 'test/accuracy_QuestionType_eight': 33.09, 'test/accuracy_QuestionType_other': 34.28, 'test/accuracy_QuestionType_seven': 33.74, 'test/accuracy_QuestionType_four': 44.62, 'test/accuracy_QuestionType_five': 33.42, 'test/accuracy_QuestionType_three': 31.4, 'test/accuracy_QuestionType_nine': 29.29, 'test/accuracy_QuestionType_ten': 38.45, 'test/accuracy_QuestionType_two': 29.77, 'test/accuracy_QuestionType_six': 30.21, 'test/accuracy_AnswerType_other': 33.86, 'test/epoch': 12}[0m
Epoch 12, global step 3666: 'test/accuracy_overall' reached 33.86000 (best 33.86000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435/train/saved_model/model_12.ckpt' as top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 34.02, 'test/accuracy_QuestionType_one': 30.36, 'test/accuracy_QuestionType_eight': 31.47, 'test/accuracy_QuestionType_other': 35.15, 'test/accuracy_QuestionType_seven': 32.2, 'test/accuracy_QuestionType_four': 45.33, 'test/accuracy_QuestionType_five': 33.79, 'test/accuracy_QuestionType_three': 33.93, 'test/accuracy_QuestionType_nine': 30.95, 'test/accuracy_QuestionType_ten': 41.71, 'test/accuracy_QuestionType_two': 29.53, 'test/accuracy_QuestionType_six': 27.66, 'test/accuracy_AnswerType_other': 34.02, 'test/epoch': 13}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 33.95, 'test/accuracy_QuestionType_one': 29.57, 'test/accuracy_QuestionType_eight': 33.67, 'test/accuracy_QuestionType_other': 33.99, 'test/accuracy_QuestionType_seven': 32.85, 'test/accuracy_QuestionType_four': 46.84, 'test/accuracy_QuestionType_five': 32.22, 'test/accuracy_QuestionType_three': 30.98, 'test/accuracy_QuestionType_nine': 30.0, 'test/accuracy_QuestionType_ten': 41.86, 'test/accuracy_QuestionType_two': 30.81, 'test/accuracy_QuestionType_six': 29.93, 'test/accuracy_AnswerType_other': 33.95, 'test/epoch': 13}[0m
Epoch 13, global step 3948: 'test/accuracy_overall' reached 33.95000 (best 33.95000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435/train/saved_model/model_13.ckpt' as top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 33.54, 'test/accuracy_QuestionType_one': 28.95, 'test/accuracy_QuestionType_eight': 32.74, 'test/accuracy_QuestionType_other': 33.47, 'test/accuracy_QuestionType_seven': 33.55, 'test/accuracy_QuestionType_four': 45.08, 'test/accuracy_QuestionType_five': 33.12, 'test/accuracy_QuestionType_three': 32.76, 'test/accuracy_QuestionType_nine': 29.29, 'test/accuracy_QuestionType_ten': 37.83, 'test/accuracy_QuestionType_two': 30.47, 'test/accuracy_QuestionType_six': 25.96, 'test/accuracy_AnswerType_other': 33.54, 'test/epoch': 14}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 33.79, 'test/accuracy_QuestionType_one': 29.13, 'test/accuracy_QuestionType_eight': 32.84, 'test/accuracy_QuestionType_other': 34.93, 'test/accuracy_QuestionType_seven': 32.52, 'test/accuracy_QuestionType_four': 45.5, 'test/accuracy_QuestionType_five': 31.68, 'test/accuracy_QuestionType_three': 34.72, 'test/accuracy_QuestionType_nine': 28.1, 'test/accuracy_QuestionType_ten': 38.91, 'test/accuracy_QuestionType_two': 31.05, 'test/accuracy_QuestionType_six': 29.5, 'test/accuracy_AnswerType_other': 33.79, 'test/epoch': 14}[0m
Epoch 14, global step 4230: 'test/accuracy_overall' was not in top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 34.19, 'test/accuracy_QuestionType_one': 29.32, 'test/accuracy_QuestionType_eight': 32.95, 'test/accuracy_QuestionType_other': 34.44, 'test/accuracy_QuestionType_seven': 33.41, 'test/accuracy_QuestionType_four': 46.14, 'test/accuracy_QuestionType_five': 33.91, 'test/accuracy_QuestionType_three': 32.76, 'test/accuracy_QuestionType_nine': 28.1, 'test/accuracy_QuestionType_ten': 39.69, 'test/accuracy_QuestionType_two': 32.56, 'test/accuracy_QuestionType_six': 29.65, 'test/accuracy_AnswerType_other': 34.19, 'test/epoch': 15}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 34.34, 'test/accuracy_QuestionType_one': 30.33, 'test/accuracy_QuestionType_eight': 32.77, 'test/accuracy_QuestionType_other': 34.67, 'test/accuracy_QuestionType_seven': 30.84, 'test/accuracy_QuestionType_four': 46.35, 'test/accuracy_QuestionType_five': 34.66, 'test/accuracy_QuestionType_three': 33.04, 'test/accuracy_QuestionType_nine': 31.43, 'test/accuracy_QuestionType_ten': 40.93, 'test/accuracy_QuestionType_two': 30.93, 'test/accuracy_QuestionType_six': 29.93, 'test/accuracy_AnswerType_other': 34.34, 'test/epoch': 15}[0m
Epoch 15, global step 4512: 'test/accuracy_overall' reached 34.34000 (best 34.34000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435/train/saved_model/model_15.ckpt' as top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 34.31, 'test/accuracy_QuestionType_one': 29.99, 'test/accuracy_QuestionType_eight': 32.88, 'test/accuracy_QuestionType_other': 34.89, 'test/accuracy_QuestionType_seven': 32.29, 'test/accuracy_QuestionType_four': 46.07, 'test/accuracy_QuestionType_five': 33.71, 'test/accuracy_QuestionType_three': 33.55, 'test/accuracy_QuestionType_nine': 30.0, 'test/accuracy_QuestionType_ten': 38.6, 'test/accuracy_QuestionType_two': 30.81, 'test/accuracy_QuestionType_six': 32.77, 'test/accuracy_AnswerType_other': 34.31, 'test/epoch': 16}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 34.58, 'test/accuracy_QuestionType_one': 29.42, 'test/accuracy_QuestionType_eight': 33.0, 'test/accuracy_QuestionType_other': 35.35, 'test/accuracy_QuestionType_seven': 33.04, 'test/accuracy_QuestionType_four': 46.6, 'test/accuracy_QuestionType_five': 34.24, 'test/accuracy_QuestionType_three': 34.44, 'test/accuracy_QuestionType_nine': 29.52, 'test/accuracy_QuestionType_ten': 40.16, 'test/accuracy_QuestionType_two': 30.93, 'test/accuracy_QuestionType_six': 31.77, 'test/accuracy_AnswerType_other': 34.58, 'test/epoch': 16}[0m
Epoch 16, global step 4794: 'test/accuracy_overall' reached 34.58000 (best 34.58000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435/train/saved_model/model_16.ckpt' as top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 34.13, 'test/accuracy_QuestionType_one': 28.78, 'test/accuracy_QuestionType_eight': 33.58, 'test/accuracy_QuestionType_other': 34.38, 'test/accuracy_QuestionType_seven': 33.32, 'test/accuracy_QuestionType_four': 45.29, 'test/accuracy_QuestionType_five': 33.17, 'test/accuracy_QuestionType_three': 33.27, 'test/accuracy_QuestionType_nine': 28.81, 'test/accuracy_QuestionType_ten': 41.4, 'test/accuracy_QuestionType_two': 31.51, 'test/accuracy_QuestionType_six': 32.77, 'test/accuracy_AnswerType_other': 34.13, 'test/epoch': 17}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 34.58, 'test/accuracy_QuestionType_one': 30.26, 'test/accuracy_QuestionType_eight': 33.51, 'test/accuracy_QuestionType_other': 35.38, 'test/accuracy_QuestionType_seven': 33.04, 'test/accuracy_QuestionType_four': 45.75, 'test/accuracy_QuestionType_five': 33.79, 'test/accuracy_QuestionType_three': 33.79, 'test/accuracy_QuestionType_nine': 28.1, 'test/accuracy_QuestionType_ten': 39.84, 'test/accuracy_QuestionType_two': 32.44, 'test/accuracy_QuestionType_six': 30.92, 'test/accuracy_AnswerType_other': 34.58, 'test/epoch': 17}[0m
Epoch 17, global step 5076: 'test/accuracy_overall' was not in top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 34.68, 'test/accuracy_QuestionType_one': 29.72, 'test/accuracy_QuestionType_eight': 33.91, 'test/accuracy_QuestionType_other': 35.32, 'test/accuracy_QuestionType_seven': 32.99, 'test/accuracy_QuestionType_four': 46.46, 'test/accuracy_QuestionType_five': 34.11, 'test/accuracy_QuestionType_three': 33.64, 'test/accuracy_QuestionType_nine': 27.62, 'test/accuracy_QuestionType_ten': 41.24, 'test/accuracy_QuestionType_two': 30.47, 'test/accuracy_QuestionType_six': 32.77, 'test/accuracy_AnswerType_other': 34.68, 'test/epoch': 18}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 34.54, 'test/accuracy_QuestionType_one': 29.4, 'test/accuracy_QuestionType_eight': 33.35, 'test/accuracy_QuestionType_other': 35.54, 'test/accuracy_QuestionType_seven': 33.27, 'test/accuracy_QuestionType_four': 46.17, 'test/accuracy_QuestionType_five': 33.84, 'test/accuracy_QuestionType_three': 33.74, 'test/accuracy_QuestionType_nine': 26.19, 'test/accuracy_QuestionType_ten': 40.47, 'test/accuracy_QuestionType_two': 33.26, 'test/accuracy_QuestionType_six': 31.77, 'test/accuracy_AnswerType_other': 34.54, 'test/epoch': 18}[0m
Epoch 18, global step 5358: 'test/accuracy_overall' was not in top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 34.8, 'test/accuracy_QuestionType_one': 29.79, 'test/accuracy_QuestionType_eight': 33.74, 'test/accuracy_QuestionType_other': 35.67, 'test/accuracy_QuestionType_seven': 33.13, 'test/accuracy_QuestionType_four': 46.35, 'test/accuracy_QuestionType_five': 34.36, 'test/accuracy_QuestionType_three': 33.97, 'test/accuracy_QuestionType_nine': 27.38, 'test/accuracy_QuestionType_ten': 40.47, 'test/accuracy_QuestionType_two': 32.67, 'test/accuracy_QuestionType_six': 31.63, 'test/accuracy_AnswerType_other': 34.8, 'test/epoch': 19}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.t5_executor_with_prefix : Evaluation results [validate]: {'test/accuracy_overall': 34.82, 'test/accuracy_QuestionType_one': 29.47, 'test/accuracy_QuestionType_eight': 33.53, 'test/accuracy_QuestionType_other': 35.48, 'test/accuracy_QuestionType_seven': 32.9, 'test/accuracy_QuestionType_four': 46.98, 'test/accuracy_QuestionType_five': 34.61, 'test/accuracy_QuestionType_three': 33.97, 'test/accuracy_QuestionType_nine': 27.38, 'test/accuracy_QuestionType_ten': 41.55, 'test/accuracy_QuestionType_two': 32.67, 'test/accuracy_QuestionType_six': 32.06, 'test/accuracy_AnswerType_other': 34.82, 'test/epoch': 19}[0m
Epoch 19, global step 5640: 'test/accuracy_overall' reached 34.82000 (best 34.82000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_NoDPR-flanT5-qf.22963435/train/saved_model/model_19.ckpt' as top 1
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: | 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: / 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: - 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: \ 0.015 MB of 0.015 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                                     epoch ▁▁▁▁▂▂▂▂▃▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇████
wandb:            test/accuracy_AnswerType_other ▄▁▅▄▁▄▅▅▃▄▆▆▆▇▅▇▇▇██
wandb:   test/accuracy_AnswerType_other_auto_max ▁▃▃▃▃▅▇▇▇█
wandb:   test/accuracy_AnswerType_other_auto_min ██▁▁▁▁▁▁▁▁
wandb:          test/accuracy_QuestionType_eight ▆▁▇▇▄▇▄█▆▆▆▆▆▇▇▇█▇█▇
wandb: test/accuracy_QuestionType_eight_auto_max ▁▄▄▇▇▇▇▇██
wandb: test/accuracy_QuestionType_eight_auto_min ▁▁▁▁▁▁▁▁▁▁
wandb:           test/accuracy_QuestionType_five ▁▂▃▂▅▅▆▂▄▁▆█▆▇▄▆▇▆▇█
wandb:  test/accuracy_QuestionType_five_auto_max ▁▃▅▆▆█████
wandb:  test/accuracy_QuestionType_five_auto_min ████▁▁▁▁▁▁
wandb:           test/accuracy_QuestionType_four ▅▅▃▂▁▅▆█▅▆▇▇▇▇▆▆▇▇▇█
wandb:  test/accuracy_QuestionType_four_auto_max ▁▁▁███████
wandb:  test/accuracy_QuestionType_four_auto_min █▃▁▁▁▁▁▁▁▁
wandb:           test/accuracy_QuestionType_nine ▂▃▅▅▅▅▇▆▅▄▄█▆▅▄▄▃▁▃▃
wandb:  test/accuracy_QuestionType_nine_auto_max ▁▄▄▇▇█████
wandb:  test/accuracy_QuestionType_nine_auto_min ████████▁▁
wandb:            test/accuracy_QuestionType_one █▅▄▅▁▅▆▄▂▃▃▆▅▃▁▆▄▃▄▄
wandb:   test/accuracy_QuestionType_one_auto_max ▁▁▁▁▁▁▁▁▁▁
wandb:   test/accuracy_QuestionType_one_auto_min █▇▁▁▁▁▁▁▁▁
wandb:          test/accuracy_QuestionType_other ▅▇▆▅▁▄▆▃▂▆▄▅▆▇▄▇▇██▇
wandb: test/accuracy_QuestionType_other_auto_max ▁▁▁▁▁▁▂▃▆█
wandb: test/accuracy_QuestionType_other_auto_min ██▁▁▁▁▁▁▁▁
wandb:          test/accuracy_QuestionType_seven ▄▂█▅▃█▄▆▇▅▇▁▄▆▇▆▆▇▆▆
wandb: test/accuracy_QuestionType_seven_auto_max ▁█████████
wandb: test/accuracy_QuestionType_seven_auto_min █████▁▁▁▁▁
wandb:            test/accuracy_QuestionType_six ▂▃▂▄▆▅▃▅▁▅▅▅█▇█▆█▇▇▇
wandb:   test/accuracy_QuestionType_six_auto_max ▁▃▆▆▆▆████
wandb:   test/accuracy_QuestionType_six_auto_min ████▁▁▁▁▁▁
wandb:            test/accuracy_QuestionType_ten ▇█▇▆▂▂▇█▁▃▄▆▂▅▇▄▇▅▅▇
wandb:   test/accuracy_QuestionType_ten_auto_max ▁▁▁▁▁▁▁▁▁▁
wandb:   test/accuracy_QuestionType_ten_auto_min █▇▂▂▁▁▁▁▁▁
wandb:          test/accuracy_QuestionType_three ▄▅▆▇▄▂▇▁▄█▄▅▆▇▅▆▆▆▇▇
wandb: test/accuracy_QuestionType_three_auto_max ▁▅▅▅██████
wandb: test/accuracy_QuestionType_three_auto_min ██▃▁▁▁▁▁▁▁
wandb:            test/accuracy_QuestionType_two ▃▁▃▃▅▄▃▅▄▅▇▅▅▅▆▇▄█▇▇
wandb:   test/accuracy_QuestionType_two_auto_max ▁▁▄▄▄▇▇▇██
wandb:   test/accuracy_QuestionType_two_auto_min ▁▁▁▁▁▁▁▁▁▁
wandb:                     test/accuracy_overall ▄▁▅▄▁▄▅▅▃▄▆▆▆▇▅▇▇▇██
wandb:            test/accuracy_overall_auto_max ▁▃▃▃▃▅▇▇▇█
wandb:            test/accuracy_overall_auto_min ██▁▁▁▁▁▁▁▁
wandb:                                test/epoch ▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇██
wandb:                       test/epoch_auto_max ▁▂▃▃▄▅▆▆▇█
wandb:                       test/epoch_auto_min ▁▁▁▁▁▁▁▁▁▁
wandb:                          train/loss_epoch █▅▄▃▁▁▁▁▃▄
wandb:                 train/loss_epoch_auto_max ▁▁▁▁▁▁▁▁▁
wandb:                 train/loss_epoch_auto_min █▅▄▃▁▁▁▁▁
wandb:                           train/loss_step ▄▂▁▃▁▃▃█▂▃▂▂▂▃▃▄▃▁▁▂▁▇▂▃▁▃▂▂▃▃▃▃▇▂▂▄▁▃▃▃
wandb:                  train/loss_step_auto_max ▁▃████████
wandb:                  train/loss_step_auto_min █▄▄▁▁▁▁▁▁▁
wandb:                               train/lr[0] ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:                      train/lr[0]_auto_max ▁▁▁▁▁▁▁▁▁▁
wandb:                      train/lr[0]_auto_min █▇▆▆▅▄▃▃▂▁
wandb:                               train/lr[1] ███▇▇▇▇▇▇▆▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁
wandb:                      train/lr[1]_auto_max ▁▁▁▁▁▁▁▁▁▁
wandb:                      train/lr[1]_auto_min █▇▆▆▅▄▃▃▂▁
wandb:                       trainer/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb: 
wandb: Run summary:
wandb:                                     epoch 19
wandb:            test/accuracy_AnswerType_other 34.82
wandb:   test/accuracy_AnswerType_other_auto_max 34.82
wandb:   test/accuracy_AnswerType_other_auto_min 32.92
wandb:          test/accuracy_QuestionType_eight 33.53
wandb: test/accuracy_QuestionType_eight_auto_max 33.91
wandb: test/accuracy_QuestionType_eight_auto_min 29.44
wandb:           test/accuracy_QuestionType_five 34.61
wandb:  test/accuracy_QuestionType_five_auto_max 34.66
wandb:  test/accuracy_QuestionType_five_auto_min 31.68
wandb:           test/accuracy_QuestionType_four 46.98
wandb:  test/accuracy_QuestionType_four_auto_max 46.98
wandb:  test/accuracy_QuestionType_four_auto_min 42.01
wandb:           test/accuracy_QuestionType_nine 27.38
wandb:  test/accuracy_QuestionType_nine_auto_max 31.43
wandb:  test/accuracy_QuestionType_nine_auto_min 26.19
wandb:            test/accuracy_QuestionType_one 29.47
wandb:   test/accuracy_QuestionType_one_auto_max 31.0
wandb:   test/accuracy_QuestionType_one_auto_min 28.61
wandb:          test/accuracy_QuestionType_other 35.48
wandb: test/accuracy_QuestionType_other_auto_max 35.67
wandb: test/accuracy_QuestionType_other_auto_min 33.28
wandb:          test/accuracy_QuestionType_seven 32.9
wandb: test/accuracy_QuestionType_seven_auto_max 33.93
wandb: test/accuracy_QuestionType_seven_auto_min 30.84
wandb:            test/accuracy_QuestionType_six 32.06
wandb:   test/accuracy_QuestionType_six_auto_max 32.77
wandb:   test/accuracy_QuestionType_six_auto_min 25.96
wandb:            test/accuracy_QuestionType_ten 41.55
wandb:   test/accuracy_QuestionType_ten_auto_max 42.17
wandb:   test/accuracy_QuestionType_ten_auto_min 37.83
wandb:          test/accuracy_QuestionType_three 33.97
wandb: test/accuracy_QuestionType_three_auto_max 34.72
wandb: test/accuracy_QuestionType_three_auto_min 30.98
wandb:            test/accuracy_QuestionType_two 32.67
wandb:   test/accuracy_QuestionType_two_auto_max 33.26
wandb:   test/accuracy_QuestionType_two_auto_min 27.79
wandb:                     test/accuracy_overall 34.82
wandb:            test/accuracy_overall_auto_max 34.82
wandb:            test/accuracy_overall_auto_min 32.92
wandb:                                test/epoch 19.0
wandb:                       test/epoch_auto_max 19.0
wandb:                       test/epoch_auto_min 10.0
wandb:                          train/loss_epoch 0.7064
wandb:                 train/loss_epoch_auto_max 0.90183
wandb:                 train/loss_epoch_auto_min 0.58176
wandb:                           train/loss_step 0.01683
wandb:                  train/loss_step_auto_max 3.26109
wandb:                  train/loss_step_auto_min 4e-05
wandb:                               train/lr[0] 0.0
wandb:                      train/lr[0]_auto_max 3e-05
wandb:                      train/lr[0]_auto_min 0.0
wandb:                               train/lr[1] 0.0
wandb:                      train/lr[1]_auto_max 5e-05
wandb:                      train/lr[1]_auto_min 0.0
wandb:                       trainer/global_step 5639
wandb: 
wandb: 🚀 View run OKVQA_NoDPR-flanT5-qf.22963435 at: https://wandb.ai/xl544/RAVQA/runs/6ka148e2
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230625_161939-6ka148e2/logs
