/home/xl544/.conda/envs/RAVQA/lib/python3.8/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning
  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')
[38;20m[INFO] - __main__ : Initialization done with the config: {'DATA_FOLDER': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Data', 'EXPERIMENT_FOLDER': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments', 'TENSORBOARD_FOLDER': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Data_TB/tb_logs', 'WANDB': {'entity': 'xl544', 'project': 'RAVQA', 'tags': ['OKVQA', 'RAG', 'freeze_question_encoder', 'force_existence'], 'name': 'OKVQA_RA-VQA-T5-qformer-flan.21921249'}, 'cache': {'default_folder': '../data/ok-vqa/cache', 'regenerate': {'clip_embeddings': 0, 'ocr_feature_preprocessed': 0, 'qformer_embeddings': 0, 'test_data_preprocessed': 0, 'train_data_preprocessed': 0, 'vinvl_feature_preprocessed': 0}}, 'cuda': 0, 'data_loader': {'additional': {'max_decoder_source_length': 512, 'max_source_length': 512, 'max_target_length': 10, 'num_knowledge_passages': 5}, 'dataset_modules': {'module_dict': {'LoadClipEmbeddings': {'config': {'clip_embeddings': {'train': '../data/ok-vqa/pre-extracted_features/clip_embeddings/coco_ViT-L_14@336px_train2014.pkl', 'val': '../data/ok-vqa/pre-extracted_features/clip_embeddings/coco_ViT-L_14@336px_val2014.pkl'}, 'qformer_embeddings': {'train': '../data/ok-vqa/pre-extracted_features/blip2_head_embeddings/coco_eva_clip_g_qformer_train2014.pkl', 'val': '../data/ok-vqa/pre-extracted_features/blip2_head_embeddings/coco_eva_clip_g_qformer_val2014.pkl'}}, 'option': 'default', 'type': 'EmbeddingInput'}, 'LoadGoogleOCRFeatures': {'config': {'combine_with_vinvl': True, 'test': '../data/ok-vqa/pre-extracted_features/OCR/valid', 'train': '../data/ok-vqa/pre-extracted_features/OCR/train'}, 'option': 'default', 'type': 'LoadGoogleOCRFeatures'}, 'LoadGoogleSearchAnnotations': {'config': {'annotations_path': {'test': '../data/ok-vqa/pre-extracted_features/passages/retriever_test.json', 'train': '../data/ok-vqa/pre-extracted_features/passages/retriever_train.json', 'valid': '../data/ok-vqa/pre-extracted_features/passages/retriever_testdev.json'}}, 'option': 'default', 'type': 'LoadGoogleSearchAnnotations'}, 'LoadGoogleSearchPassageData': {'config': {'passage_data_path': {'full': '../data/ok-vqa/pre-extracted_features/passages/okvqa_full_corpus.csv', 'train': '../data/ok-vqa/pre-extracted_features/passages/okvqa_train_corpus.csv'}, 'use_full_split': True}, 'option': 'default', 'type': 'LoadGoogleSearchPassageData'}, 'LoadOKVQAData': {'config': {'image_data_path': {'test': '../data/ok-vqa/val2014', 'train': '../data/ok-vqa/train2014'}, 'vqa_data_path': {'annotation_files': {'test': '../data/ok-vqa/mscoco_val2014_annotations.json', 'train': '../data/ok-vqa/mscoco_train2014_annotations.json'}, 'question_files': {'test': '../data/ok-vqa/OpenEnded_mscoco_val2014_questions.json', 'train': '../data/ok-vqa/OpenEnded_mscoco_train2014_questions.json'}}}, 'option': 'default', 'type': 'LoadOKVQAData'}, 'LoadOscarCaptionFeatures': {'config': {'test': '../data/ok-vqa/pre-extracted_features/captions/test_predictions.json', 'train': '../data/ok-vqa/pre-extracted_features/captions/train_predictions.json', 'valid': '../data/ok-vqa/pre-extracted_features/captions/valid_predictions.json'}, 'option': 'default', 'type': 'LoadOscarCaptionFeatures'}, 'LoadPretrainedDPROutputForGoogleSearchPassage': {'config': {'pretrained_dpr_outputs': {'test': '../Experiments/Knowledge_Retriever_DPR_dim_768_inbatch_negative_caption_FullCorpus_NewRun/test/test_evaluation/test_predictions.json', 'train': '../Experiments/Knowledge_Retriever_DPR_dim_768_inbatch_negative_caption_FullCorpus_NewRun/test/test_evaluation/train_predictions.json'}}, 'option': 'none', 'type': 'LoadPretrainedDPROutputForGoogleSearchPassage'}, 'LoadVinVLFeatures': {'config': {'test': '../data/ok-vqa/pre-extracted_features/vinvl_output/vinvl_okvqa_testset_full/inference/vinvl_vg_x152c4/predictions.tsv', 'train': '../data/ok-vqa/pre-extracted_features/vinvl_output/vinvl_okvqa_trainset_full/inference/vinvl_vg_x152c4/predictions.tsv'}, 'option': 'default', 'type': 'LoadVinVLFeatures'}}, 'module_list': ['LoadVinVLFeatures', 'LoadGoogleOCRFeatures', 'LoadOscarCaptionFeatures', 'LoadOKVQAData', 'LoadGoogleSearchPassageData', 'LoadClipEmbeddings']}, 'dataset_type': 'OKVQADataset', 'dummy_dataloader': 0, 'index_files': {'index_passages_path': '../data/ok-vqa/pre-extracted_features/faiss/ok-vqa-passages-full-caption-pretrained-NewRun/my_knowledge_dataset', 'index_path': '../data/ok-vqa/pre-extracted_features/faiss/ok-vqa-passages-full-caption-pretrained-NewRun/my_knowledge_dataset_hnsw_index.faiss'}, 'type': 'DataLoaderOKVQAWithKnowledge'}, 'experiment_name': 'OKVQA_RA-VQA-T5-qformer-flan.21921249', 'gpu_device': 0, 'ignore_pretrained_weights': [], 'metrics': [{'name': 'compute_exact_match'}, {'name': 'compute_retrieval_metrics'}, {'name': 'compute_okvqa_scores'}], 'model_config': {' ': 0, 'DECODER_SPECIAL_TOKENS': {'additional_special_tokens': ['<BOV>', '<SOV>', '<EOV>', '<BOQ>', '<EOQ>', '<BOC>', '<EOC>', '<BOK>', '<EOK>'], 'bos_token': '<PAD>', 'pad_token': '<PAD>'}, 'DecoderTokenizerClass': 'T5Tokenizer', 'DecoderTokenizerModelVersion': 'google/flan-t5-large', 'GeneratorConfigClass': 'T5Config', 'GeneratorModelClass': 'T5ForConditionalGeneration', 'GeneratorModelVersion': 'google/flan-t5-large', 'LoadPretrainedMLPWeights': 0, 'ModelClass': 'RagModel', 'PretrainedMLPPath': '', 'QueryEncoderConfigClass': 'DPRConfig', 'QueryEncoderModelClass': 'DPRQuestionEncoder', 'QueryEncoderModelVersion': '../Experiments/Knowledge_Retriever_DPR_dim_768_inbatch_negative_caption_FullCorpus_NewRun/train/saved_model/epoch6/query_encoder', 'RAVQA_loss_type': 'Approach6', 'SPECIAL_TOKENS': {'additional_special_tokens': ['<BOV>', '<SOV>', '<EOV>', '<BOQ>', '<EOQ>', '<BOC>', '<EOC>', '<BOK>', '<EOK>']}, 'TokenizerClass': 'DPRQuestionEncoderTokenizer', 'TokenizerModelVersion': 'facebook/dpr-question_encoder-single-nq-base', 'UsePrefixEmb': 0.5, 'base_model': 'RAG', 'decoder_input_modules': {'module_list': [], 'postprocess_module_list': []}, 'input_modules': {'module_list': [{'option': 'default', 'separation_tokens': {'end': '<EOQ>', 'start': '<BOQ>'}, 'type': 'QuestionInput'}, {'option': 'caption', 'separation_tokens': {'end': '<EOC>', 'start': '<BOC>'}, 'type': 'TextBasedVisionInput'}, {'attribute_max': 3, 'attribute_thres': 0.05, 'object_max': 40, 'ocr': 1, 'option': 'object', 'separation_tokens': {'end': '<EOV>', 'sep': '<SOV>', 'start': '<BOV>'}, 'type': 'TextBasedVisionInput'}, {'option': 'default', 'type': 'EmbeddingInput'}], 'postprocess_module_list': [{'option': 'default', 'type': 'PostProcessInputTokenization'}, {'option': 'default', 'type': 'PostProcessClipEmbeddings'}]}, 'loss_ratio': {'additional_loss': 0, 'nll_loss': 1, 'rag_loss': 0, 'retrieval_pseudo_loss': 0}, 'modules': ['freeze_question_encoder', 'force_existence'], 'output_modules': {'module_list': [{'option': 'default', 'type': 'GenerationOutput'}], 'postprocess_module_list': [{'option': 'default', 'type': 'PostProcessOutputTokenization'}]}, 'pretrained': 1, 'rag_modules': {'module_list': []}, 'UseQformerEmb': 1}, 'platform_type': 'pytorch', 'seed': 2021, 'test': {'additional': {'multiprocessing': 4}, 'batch_size': 32, 'evaluation_name': 'test_evaluation', 'load_best_model': 0, 'load_epoch': -1, 'load_model_path': '', 'num_evaluation': 0}, 'train': {'adam_epsilon': 1e-08, 'additional': {'gradient_accumulation_steps': 16, 'gradient_clipping': 0, 'plugins': [], 'save_top_k': 1, 'save_top_k_metric': 'test/accuracy_overall', 'save_top_k_mode': 'max', 'warmup_steps': 0}, 'batch_size': 2, 'epochs': 8, 'load_best_model': 0, 'load_epoch': -1, 'load_model_path': '', 'lr': 6e-05, 'retriever_lr': 1e-05, 'save_interval': 1, 'scheduler': 'linear', 'type': 'RagExecutor'}, 'valid': {'additional': {}, 'batch_size': 32, 'break_interval': 3000, 'step_size': 0.5}, 'reset': False, 'mode': 'train', 'log_path': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249/train', 'experiment_path': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249', 'saved_model_path': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249/train/saved_model', 'imgs_path': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249/train/imgs', 'tensorboard_path': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Data_TB/tb_logs/OKVQA_RA-VQA-T5-qformer-flan.21921249', 'args': {'config': '../configs/okvqa/RAVQA.jsonnet', 'DATA_FOLDER': '', 'EXPERIMENT_FOLDER': '', 'mode': 'train', 'reset': False, 'experiment_name': 'OKVQA_RA-VQA-T5-qformer-flan.21921249', 'tags': [], 'modules': ['freeze_question_encoder', 'force_existence'], 'log_prediction_tables': False, 'test_batch_size': -1, 'test_evaluation_name': '', 'logger': True, 'checkpoint_callback': None, 'enable_checkpointing': True, 'default_root_dir': None, 'gradient_clip_val': None, 'gradient_clip_algorithm': None, 'process_position': 0, 'num_nodes': 1, 'num_processes': None, 'devices': '1', 'gpus': None, 'auto_select_gpus': False, 'tpu_cores': None, 'ipus': None, 'log_gpu_memory': None, 'progress_bar_refresh_rate': None, 'enable_progress_bar': True, 'overfit_batches': 0.0, 'track_grad_norm': -1, 'check_val_every_n_epoch': 1, 'fast_dev_run': False, 'accumulate_grad_batches': None, 'max_epochs': None, 'min_epochs': None, 'max_steps': -1, 'min_steps': None, 'max_time': None, 'limit_train_batches': None, 'limit_val_batches': None, 'limit_test_batches': None, 'limit_predict_batches': None, 'val_check_interval': None, 'flush_logs_every_n_steps': None, 'log_every_n_steps': 50, 'accelerator': 'auto', 'strategy': None, 'sync_batchnorm': False, 'precision': 32, 'enable_model_summary': True, 'weights_summary': 'top', 'weights_save_path': None, 'num_sanity_val_steps': 2, 'resume_from_checkpoint': None, 'profiler': None, 'benchmark': None, 'deterministic': None, 'reload_dataloaders_every_n_epochs': 0, 'auto_lr_find': False, 'replace_sampler_ddp': True, 'detect_anomaly': False, 'auto_scale_batch_size': False, 'prepare_data_per_node': None, 'plugins': None, 'amp_backend': 'native', 'amp_level': None, 'move_metrics_to_cpu': False, 'multiple_trainloader_mode': 'max_size_cycle', 'stochastic_weight_avg': False, 'terminate_on_nan': None, 'opts': ['train.epochs=8', 'train.batch_size=2', 'valid.step_size=0.5', 'valid.batch_size=32', 'train.additional.gradient_accumulation_steps=16', 'train.lr=0.00006', 'train.retriever_lr=0.00001', 'train.scheduler=linear', 'data_loader.additional.num_knowledge_passages=5', 'model_config.UseQformerEmb=1', 'model_config.UsePrefixEmb=0.5', 'model_config.DecoderTokenizerModelVersion=google/flan-t5-large', 'model_config.GeneratorModelVersion=google/flan-t5-large']}}[0m
Global seed set to 2021
[38;20m[INFO] - __main__ : All seeds have been set to 2021[0m
[38;20m[INFO] - __main__ : init wandb logger with the following settings: {'entity': 'xl544', 'project': 'RAVQA', 'tags': ['OKVQA', 'RAG', 'freeze_question_encoder', 'force_existence'], 'name': 'OKVQA_RA-VQA-T5-qformer-flan.21921249'}[0m
wandb: Currently logged in as: xl544. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.2
wandb: Run data is saved locally in /rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/src/wandb/run-20230609_014946-is6hfjv8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run OKVQA_RA-VQA-T5-qformer-flan.21921249
wandb: ‚≠êÔ∏è View project at https://wandb.ai/xl544/RAVQA
wandb: üöÄ View run at https://wandb.ai/xl544/RAVQA/runs/is6hfjv8
Multiprocessing is handled by SLURM.
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
[38;20m[INFO] - __main__ : arguments passed to trainer: Namespace(DATA_FOLDER='', EXPERIMENT_FOLDER='', accelerator='auto', accumulate_grad_batches=None, amp_backend='native', amp_level=None, auto_lr_find=False, auto_scale_batch_size=False, auto_select_gpus=False, benchmark=None, check_val_every_n_epoch=1, checkpoint_callback=None, config='../configs/okvqa/RAVQA.jsonnet', default_root_dir=None, detect_anomaly=False, deterministic=None, devices='1', enable_checkpointing=True, enable_model_summary=True, enable_progress_bar=True, experiment_name='OKVQA_RA-VQA-T5-qformer-flan.21921249', fast_dev_run=False, flush_logs_every_n_steps=None, gpus=None, gradient_clip_algorithm=None, gradient_clip_val=None, ipus=None, limit_predict_batches=None, limit_test_batches=None, limit_train_batches=None, limit_val_batches=None, log_every_n_steps=50, log_gpu_memory=None, log_prediction_tables=False, logger=True, max_epochs=None, max_steps=-1, max_time=None, min_epochs=None, min_steps=None, mode='train', modules=['freeze_question_encoder', 'force_existence'], move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', num_nodes=1, num_processes=None, num_sanity_val_steps=2, opts=['train.epochs=8', 'train.batch_size=2', 'valid.step_size=0.5', 'valid.batch_size=32', 'train.additional.gradient_accumulation_steps=16', 'train.lr=0.00006', 'train.retriever_lr=0.00001', 'train.scheduler=linear', 'data_loader.additional.num_knowledge_passages=5', 'model_config.UseQformerEmb=1', 'model_config.UsePrefixEmb=0.5', 'model_config.DecoderTokenizerModelVersion=google/flan-t5-large', 'model_config.GeneratorModelVersion=google/flan-t5-large'], overfit_batches=0.0, plugins=None, precision=32, prepare_data_per_node=None, process_position=0, profiler=None, progress_bar_refresh_rate=None, reload_dataloaders_every_n_epochs=0, replace_sampler_ddp=True, reset=False, resume_from_checkpoint=None, stochastic_weight_avg=False, strategy=None, sync_batchnorm=False, tags=[], terminate_on_nan=None, test_batch_size=-1, test_evaluation_name='', tpu_cores=None, track_grad_norm=-1, val_check_interval=None, weights_save_path=None, weights_summary='top')[0m
[38;20m[INFO] - __main__ : additional arguments passed to trainer: {'accumulate_grad_batches': 16, 'default_root_dir': '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249/train/saved_model', 'max_epochs': 8, 'logger': [<pytorch_lightning.loggers.tensorboard.TensorBoardLogger object at 0x15390eef6af0>, <pytorch_lightning.loggers.wandb.WandbLogger object at 0x15390ef08700>, <utils.metrics_log_callback.MetricsHistoryLogger object at 0x15390e4a4430>], 'callbacks': [<pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint object at 0x15390ef08f70>, <pytorch_lightning.callbacks.progress.tqdm_progress.TQDMProgressBar object at 0x15390e615ee0>, <pytorch_lightning.callbacks.model_summary.ModelSummary object at 0x15390e615e80>, <pytorch_lightning.callbacks.gradient_accumulation_scheduler.GradientAccumulationScheduler object at 0x15390e615c40>], 'plugins': [], 'log_every_n_steps': 10, 'val_check_interval': 0.5}[0m
[33;20m[WARNING] - __main__ : No checkpoint exists from '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249/train/saved_model/last.ckpt'. Skipping...[0m
[38;20m[INFO] - __main__ : **First time to train**[0m
[38;20m[INFO] - data_loader_manager.data_loader_wrapper : Loading dataset module: {'config': {'test': '../data/ok-vqa/pre-extracted_features/vinvl_output/vinvl_okvqa_testset_full/inference/vinvl_vg_x152c4/predictions.tsv', 'train': '../data/ok-vqa/pre-extracted_features/vinvl_output/vinvl_okvqa_trainset_full/inference/vinvl_vg_x152c4/predictions.tsv'}, 'option': 'default', 'type': 'LoadVinVLFeatures'}[0m
[38;20m[INFO] - utils.cache_system : reading preprocessed data from ../data/ok-vqa/cache/vinvl_feature_preprocessed.pkl[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : [Data Statistics] VinVL features 14031[0m
[38;20m[INFO] - data_loader_manager.data_loader_wrapper : Loading dataset module: {'config': {'combine_with_vinvl': True, 'test': '../data/ok-vqa/pre-extracted_features/OCR/valid', 'train': '../data/ok-vqa/pre-extracted_features/OCR/train'}, 'option': 'default', 'type': 'LoadGoogleOCRFeatures'}[0m
[38;20m[INFO] - utils.cache_system : reading preprocessed data from ../data/ok-vqa/cache/ocr_feature_preprocessed.pkl[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : [Data Statistics] OCR features 14031, 5462 has annotations.[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : OCR feature detected in VinVL feature dict...skipping..[0m
[38;20m[INFO] - data_loader_manager.data_loader_wrapper : Loading dataset module: {'config': {'test': '../data/ok-vqa/pre-extracted_features/captions/test_predictions.json', 'train': '../data/ok-vqa/pre-extracted_features/captions/train_predictions.json', 'valid': '../data/ok-vqa/pre-extracted_features/captions/valid_predictions.json'}, 'option': 'default', 'type': 'LoadOscarCaptionFeatures'}[0m
[38;20m[INFO] - data_loader_manager.data_loader_wrapper : Loading dataset module: {'config': {'image_data_path': {'test': '../data/ok-vqa/val2014', 'train': '../data/ok-vqa/train2014'}, 'vqa_data_path': {'annotation_files': {'test': '../data/ok-vqa/mscoco_val2014_annotations.json', 'train': '../data/ok-vqa/mscoco_train2014_annotations.json'}, 'question_files': {'test': '../data/ok-vqa/OpenEnded_mscoco_val2014_questions.json', 'train': '../data/ok-vqa/OpenEnded_mscoco_train2014_questions.json'}}}, 'option': 'default', 'type': 'LoadOKVQAData'}[0m
[38;20m[INFO] - utils.cache_system : reading preprocessed data from ../data/ok-vqa/cache/train_data_preprocessed.pkl[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : [Data statistics] split: train  entries: 9009[0m
[38;20m[INFO] - utils.cache_system : reading preprocessed data from ../data/ok-vqa/cache/test_data_preprocessed.pkl[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : [Data statistics] split: test  entries: 5046[0m
[38;20m[INFO] - data_loader_manager.data_loader_wrapper : Loading dataset module: {'config': {'passage_data_path': {'full': '../data/ok-vqa/pre-extracted_features/passages/okvqa_full_corpus.csv', 'train': '../data/ok-vqa/pre-extracted_features/passages/okvqa_train_corpus.csv'}, 'use_full_split': True}, 'option': 'default', 'type': 'LoadGoogleSearchPassageData'}[0m
  0%|          | 0/168380 [00:00<?, ?it/s] 10%|‚ñâ         | 16098/168380 [00:00<00:00, 160972.48it/s] 19%|‚ñà‚ñâ        | 32413/168380 [00:00<00:00, 162247.52it/s] 29%|‚ñà‚ñà‚ñâ       | 48762/168380 [00:00<00:00, 162811.02it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 65328/168380 [00:00<00:00, 163934.09it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 81931/168380 [00:00<00:00, 164687.52it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 98422/168380 [00:00<00:00, 164755.74it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 115463/168380 [00:00<00:00, 166601.74it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 134753/168380 [00:00<00:00, 174971.42it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 154283/168380 [00:00<00:00, 181324.77it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 168307/168380 [00:00<00:00, 173692.06it/s]
[38;20m[INFO] - data_loader_manager.data_loader_wrapper : Loading dataset module: {'config': {'clip_embeddings': {'train': '../data/ok-vqa/pre-extracted_features/clip_embeddings/coco_ViT-L_14@336px_train2014.pkl', 'val': '../data/ok-vqa/pre-extracted_features/clip_embeddings/coco_ViT-L_14@336px_val2014.pkl'}, 'qformer_embeddings': {'train': '../data/ok-vqa/pre-extracted_features/blip2_head_embeddings/coco_eva_clip_g_qformer_train2014.pkl', 'val': '../data/ok-vqa/pre-extracted_features/blip2_head_embeddings/coco_eva_clip_g_qformer_val2014.pkl'}}, 'option': 'default', 'type': 'EmbeddingInput'}[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : Reading: ../data/ok-vqa/pre-extracted_features/blip2_head_embeddings/coco_eva_clip_g_qformer_train2014.pkl[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : Reading: ../data/ok-vqa/pre-extracted_features/blip2_head_embeddings/coco_eva_clip_g_qformer_val2014.pkl[0m
[38;20m[INFO] - utils.cache_system : saving preprocessed data...[0m
[38;20m[INFO] - utils.cache_system : preprocessed data has been saved to ../data/ok-vqa/cache/qformer_embeddings.pkl[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa : [Data Statistics] CLIP embeddings 14031[0m
[38;20m[INFO] - data_loader_manager.datasets.okvqa_datasets : initialising OKVQADataset...[0m
[38;20m[INFO] - data_loader_manager.datasets.okvqa_datasets : initialising OKVQADataset...[0m
[38;20m[INFO] - data_loader_manager.data_loader_okvqa_with_knowledge : [Data Statistics]: training data loader: 4505;  test data loader: 158[0m
[38;20m[INFO] - torch.distributed.nn.jit.instantiator : Created a temporary directory at /tmp/tmpn0dyurkf[0m
[38;20m[INFO] - torch.distributed.nn.jit.instantiator : Writing /tmp/tmpn0dyurkf/_remote_module_non_scriptable.py[0m
[38;20m[INFO] - trainers.base_executor : Initializing RagExecutor...[0m
[38;20m[INFO] - __main__ : config file was successfully saved to /rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249 for future use.[0m
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
[38;20m[INFO] - trainers.rag_executor : using different learning rate for retriever[0m
[38;20m[INFO] - trainers.rag_executor : #params: 558   lr: 6e-05[0m
[38;20m[INFO] - trainers.rag_executor : #params: 2   lr: 1e-05[0m
Loading `train_dataloader` to estimate number of stepping batches.
/home/xl544/.conda/envs/RAVQA/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(

  | Name  | Type     | Params
-----------------------------------
0 | model | RagModel | 893 M 
-----------------------------------
783 M     Trainable params
109 M     Non-trainable params
893 M     Total params
3,573.559 Total estimated model params size (MB)
Missing logger folder: /rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Data_TB/tb_logs/OKVQA_RA-VQA-T5-qformer-flan.21921249/OKVQA_RA-VQA-T5-qformer-flan.21921249
SLURM auto-requeueing enabled. Setting signal handlers.
/home/xl544/.conda/envs/RAVQA/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Failed to compute OKVQA scores: Results do not correspond to current VQA set. Either the results do not have predictions for all question ids in annotation file or there is atleast one question id that does not belong to the question ids in the annotation file.This could be due to the fact that OKVQA parser requires all questions to evaluatethe accuracy. Ignore this error if this is the sanity check.[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [sanity_check]: {'test/exact_match_at_1': 0.046875, 'test/exact_match_at_2': 0.046875, 'test/exact_match_at_3': 0.0625, 'test/exact_match_at_4': 0.0625, 'test/exact_match_at_5': 0.0625, 'test/recall_at_5': 0.796875, 'test/precision_at_5': 0.515625, 'test/gold_precision_at_5': 0.328125, 'test/gold_recall_at_5': 0.625, 'test/successful_hit': 0.015625, 'test/successful_no_hit': 0.0, 'test/failed_hit': 0.565625, 'test/failed_no_hit': 0.41875, 'test/selected_successful_hit': 0.046875, 'test/selected_successful_no_hit': 0.0, 'test/selected_failed_hit': 0.515625, 'test/selected_failed_no_hit': 0.4375, 'test/n_retrieved_docs': 5, 'test/epoch': 0}[0m
[33;20m[WARNING] - root : Sanity check mode, not saving to loggers.[0m
/home/xl544/.conda/envs/RAVQA/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.523979389615537, 'test/exact_match_at_2': 0.6442726912405866, 'test/exact_match_at_3': 0.686286167261197, 'test/exact_match_at_4': 0.70055489496631, 'test/exact_match_at_5': 0.7033293697978596, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.34094332144272693, 'test/successful_no_hit': 0.13737613951644867, 'test/failed_hit': 0.33194609591755847, 'test/failed_no_hit': 0.18973444312326596, 'test/selected_successful_hit': 0.41379310344827586, 'test/selected_successful_no_hit': 0.1101862861672612, 'test/selected_failed_hit': 0.36623067776456597, 'test/selected_failed_no_hit': 0.10978993261989695, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 48.14, 'test/accuracy_QuestionType_one': 43.15, 'test/accuracy_QuestionType_eight': 46.6, 'test/accuracy_QuestionType_other': 49.31, 'test/accuracy_QuestionType_seven': 49.49, 'test/accuracy_QuestionType_four': 54.53, 'test/accuracy_QuestionType_five': 48.57, 'test/accuracy_QuestionType_three': 47.06, 'test/accuracy_QuestionType_nine': 41.43, 'test/accuracy_QuestionType_ten': 46.2, 'test/accuracy_QuestionType_two': 55.81, 'test/accuracy_QuestionType_six': 48.51, 'test/accuracy_AnswerType_other': 48.14, 'test/epoch': 0}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5410225921521997, 'test/exact_match_at_2': 0.6625049544193421, 'test/exact_match_at_3': 0.7049147839873167, 'test/exact_match_at_4': 0.7170035671819263, 'test/exact_match_at_5': 0.7201743955608403, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.35564803804994055, 'test/successful_no_hit': 0.13436385255648037, 'test/failed_hit': 0.3453824811732065, 'test/failed_no_hit': 0.16460562822037259, 'test/selected_successful_hit': 0.43876337693222356, 'test/selected_successful_no_hit': 0.10225921521997622, 'test/selected_failed_hit': 0.37158145065398335, 'test/selected_failed_no_hit': 0.08739595719381689, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 49.69, 'test/accuracy_QuestionType_one': 45.44, 'test/accuracy_QuestionType_eight': 49.14, 'test/accuracy_QuestionType_other': 50.34, 'test/accuracy_QuestionType_seven': 49.67, 'test/accuracy_QuestionType_four': 55.24, 'test/accuracy_QuestionType_five': 50.73, 'test/accuracy_QuestionType_three': 48.83, 'test/accuracy_QuestionType_nine': 42.14, 'test/accuracy_QuestionType_ten': 47.29, 'test/accuracy_QuestionType_two': 53.49, 'test/accuracy_QuestionType_six': 51.21, 'test/accuracy_AnswerType_other': 49.69, 'test/epoch': 0}[0m
/home/xl544/.conda/envs/RAVQA/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.
  warning_cache.warn(
Epoch 0, global step 282: 'test/accuracy_overall' reached 49.69000 (best 49.69000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249/train/saved_model/model_0.ckpt' as top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5596512088783194, 'test/exact_match_at_2': 0.6805390408244154, 'test/exact_match_at_3': 0.7140309155766944, 'test/exact_match_at_4': 0.7255251684502576, 'test/exact_match_at_5': 0.7281014665081252, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.35727308759413395, 'test/successful_no_hit': 0.16333729686880696, 'test/failed_hit': 0.30003963535473643, 'test/failed_no_hit': 0.17934998018232262, 'test/selected_successful_hit': 0.4340071343638526, 'test/selected_successful_no_hit': 0.1256440745144669, 'test/selected_failed_hit': 0.3335315101070155, 'test/selected_failed_no_hit': 0.10681728101466507, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 51.5, 'test/accuracy_QuestionType_one': 48.44, 'test/accuracy_QuestionType_eight': 49.63, 'test/accuracy_QuestionType_other': 53.28, 'test/accuracy_QuestionType_seven': 50.61, 'test/accuracy_QuestionType_four': 58.1, 'test/accuracy_QuestionType_five': 51.9, 'test/accuracy_QuestionType_three': 52.24, 'test/accuracy_QuestionType_nine': 38.57, 'test/accuracy_QuestionType_ten': 51.63, 'test/accuracy_QuestionType_two': 53.02, 'test/accuracy_QuestionType_six': 50.21, 'test/accuracy_AnswerType_other': 51.5, 'test/epoch': 1}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5632183908045977, 'test/exact_match_at_2': 0.6908442330558858, 'test/exact_match_at_3': 0.7281014665081252, 'test/exact_match_at_4': 0.7405866032500991, 'test/exact_match_at_5': 0.7441537851763773, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.3663892191835117, 'test/successful_no_hit': 0.1560840269520412, 'test/failed_hit': 0.3112960760998811, 'test/failed_no_hit': 0.166230677764566, 'test/selected_successful_hit': 0.44272691240586604, 'test/selected_successful_no_hit': 0.12049147839873167, 'test/selected_failed_hit': 0.3394768133174792, 'test/selected_failed_no_hit': 0.09730479587792311, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 51.74, 'test/accuracy_QuestionType_one': 48.78, 'test/accuracy_QuestionType_eight': 50.7, 'test/accuracy_QuestionType_other': 53.31, 'test/accuracy_QuestionType_seven': 52.34, 'test/accuracy_QuestionType_four': 56.9, 'test/accuracy_QuestionType_five': 53.07, 'test/accuracy_QuestionType_three': 50.09, 'test/accuracy_QuestionType_nine': 43.57, 'test/accuracy_QuestionType_ten': 52.4, 'test/accuracy_QuestionType_two': 50.47, 'test/accuracy_QuestionType_six': 49.08, 'test/accuracy_AnswerType_other': 51.74, 'test/epoch': 1}[0m
Epoch 1, global step 564: 'test/accuracy_overall' reached 51.74000 (best 51.74000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249/train/saved_model/model_1.ckpt' as top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5723345223939754, 'test/exact_match_at_2': 0.6944114149821641, 'test/exact_match_at_3': 0.7302814110186286, 'test/exact_match_at_4': 0.7391993658343242, 'test/exact_match_at_5': 0.7401902497027348, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.364367816091954, 'test/successful_no_hit': 0.17344431232659532, 'test/failed_hit': 0.2775267538644471, 'test/failed_no_hit': 0.18466111771700355, 'test/selected_successful_hit': 0.4349980182322632, 'test/selected_successful_no_hit': 0.13733650416171225, 'test/selected_failed_hit': 0.3143083630598494, 'test/selected_failed_no_hit': 0.11335711454617518, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 52.44, 'test/accuracy_QuestionType_one': 48.59, 'test/accuracy_QuestionType_eight': 51.91, 'test/accuracy_QuestionType_other': 55.35, 'test/accuracy_QuestionType_seven': 50.98, 'test/accuracy_QuestionType_four': 58.13, 'test/accuracy_QuestionType_five': 52.12, 'test/accuracy_QuestionType_three': 52.52, 'test/accuracy_QuestionType_nine': 45.48, 'test/accuracy_QuestionType_ten': 51.47, 'test/accuracy_QuestionType_two': 54.77, 'test/accuracy_QuestionType_six': 50.35, 'test/accuracy_AnswerType_other': 52.44, 'test/epoch': 2}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5755053507728894, 'test/exact_match_at_2': 0.7011494252873564, 'test/exact_match_at_3': 0.7310741181133571, 'test/exact_match_at_4': 0.7423701942132382, 'test/exact_match_at_5': 0.7445501387237415, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.36741973840665876, 'test/successful_no_hit': 0.1727705112960761, 'test/failed_hit': 0.2759809750297265, 'test/failed_no_hit': 0.18382877526753866, 'test/selected_successful_hit': 0.4399524375743163, 'test/selected_successful_no_hit': 0.13555291319857313, 'test/selected_failed_hit': 0.31074118113357113, 'test/selected_failed_no_hit': 0.11375346809353944, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 52.81, 'test/accuracy_QuestionType_one': 48.46, 'test/accuracy_QuestionType_eight': 51.47, 'test/accuracy_QuestionType_other': 54.73, 'test/accuracy_QuestionType_seven': 51.45, 'test/accuracy_QuestionType_four': 59.37, 'test/accuracy_QuestionType_five': 55.33, 'test/accuracy_QuestionType_three': 51.36, 'test/accuracy_QuestionType_nine': 45.48, 'test/accuracy_QuestionType_ten': 52.09, 'test/accuracy_QuestionType_two': 54.19, 'test/accuracy_QuestionType_six': 48.65, 'test/accuracy_AnswerType_other': 52.81, 'test/epoch': 2}[0m
Epoch 2, global step 846: 'test/accuracy_overall' reached 52.81000 (best 52.81000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249/train/saved_model/model_2.ckpt' as top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5800634165675783, 'test/exact_match_at_2': 0.6997621878715814, 'test/exact_match_at_3': 0.7330558858501783, 'test/exact_match_at_4': 0.7415774871185097, 'test/exact_match_at_5': 0.7433610780816489, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.36674593737613953, 'test/successful_no_hit': 0.17681331747919143, 'test/failed_hit': 0.2636940150614348, 'test/failed_no_hit': 0.19274673008323426, 'test/selected_successful_hit': 0.43856520015854145, 'test/selected_successful_no_hit': 0.14149821640903687, 'test/selected_failed_hit': 0.29944510503369004, 'test/selected_failed_no_hit': 0.12049147839873167, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 53.25, 'test/accuracy_QuestionType_one': 48.95, 'test/accuracy_QuestionType_eight': 52.09, 'test/accuracy_QuestionType_other': 54.96, 'test/accuracy_QuestionType_seven': 53.32, 'test/accuracy_QuestionType_four': 61.09, 'test/accuracy_QuestionType_five': 54.11, 'test/accuracy_QuestionType_three': 52.15, 'test/accuracy_QuestionType_nine': 42.38, 'test/accuracy_QuestionType_ten': 53.64, 'test/accuracy_QuestionType_two': 54.77, 'test/accuracy_QuestionType_six': 48.51, 'test/accuracy_AnswerType_other': 53.25, 'test/epoch': 3}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.581252477209671, 'test/exact_match_at_2': 0.7035275465715418, 'test/exact_match_at_3': 0.7384066587395958, 'test/exact_match_at_4': 0.7477209671026556, 'test/exact_match_at_5': 0.7495045580657946, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.36761791518034087, 'test/successful_no_hit': 0.17665477606024574, 'test/failed_hit': 0.2734046769718589, 'test/failed_no_hit': 0.1823226317875545, 'test/selected_successful_hit': 0.4425287356321839, 'test/selected_successful_no_hit': 0.13872374157748713, 'test/selected_failed_hit': 0.30122869599682917, 'test/selected_failed_no_hit': 0.1175188267934998, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 53.45, 'test/accuracy_QuestionType_one': 50.04, 'test/accuracy_QuestionType_eight': 50.77, 'test/accuracy_QuestionType_other': 56.03, 'test/accuracy_QuestionType_seven': 52.85, 'test/accuracy_QuestionType_four': 61.73, 'test/accuracy_QuestionType_five': 54.91, 'test/accuracy_QuestionType_three': 52.15, 'test/accuracy_QuestionType_nine': 42.38, 'test/accuracy_QuestionType_ten': 52.56, 'test/accuracy_QuestionType_two': 55.93, 'test/accuracy_QuestionType_six': 46.67, 'test/accuracy_AnswerType_other': 53.45, 'test/epoch': 3}[0m
Epoch 3, global step 1128: 'test/accuracy_overall' reached 53.45000 (best 53.45000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249/train/saved_model/model_3.ckpt' as top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5883868410622275, 'test/exact_match_at_2': 0.6991676575505351, 'test/exact_match_at_3': 0.7298850574712644, 'test/exact_match_at_4': 0.737217598097503, 'test/exact_match_at_5': 0.7391993658343242, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.3649623464130004, 'test/successful_no_hit': 0.1839080459770115, 'test/failed_hit': 0.24867221561632977, 'test/failed_no_hit': 0.20245739199365834, 'test/selected_successful_hit': 0.4425287356321839, 'test/selected_successful_no_hit': 0.1458581054300436, 'test/selected_failed_hit': 0.28220372572334523, 'test/selected_failed_no_hit': 0.12940943321442727, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 53.94, 'test/accuracy_QuestionType_one': 49.77, 'test/accuracy_QuestionType_eight': 52.09, 'test/accuracy_QuestionType_other': 55.8, 'test/accuracy_QuestionType_seven': 54.21, 'test/accuracy_QuestionType_four': 61.8, 'test/accuracy_QuestionType_five': 54.86, 'test/accuracy_QuestionType_three': 53.46, 'test/accuracy_QuestionType_nine': 46.43, 'test/accuracy_QuestionType_ten': 50.39, 'test/accuracy_QuestionType_two': 55.81, 'test/accuracy_QuestionType_six': 50.35, 'test/accuracy_AnswerType_other': 53.94, 'test/epoch': 4}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5856123662306778, 'test/exact_match_at_2': 0.703725723345224, 'test/exact_match_at_3': 0.7344431232659532, 'test/exact_match_at_4': 0.7429647245342846, 'test/exact_match_at_5': 0.7451446690447879, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.3697978596908442, 'test/successful_no_hit': 0.1796274276654776, 'test/failed_hit': 0.2621878715814506, 'test/failed_no_hit': 0.1883868410622275, 'test/selected_successful_hit': 0.4393579072532699, 'test/selected_successful_no_hit': 0.14625445897740785, 'test/selected_failed_hit': 0.2917162108600872, 'test/selected_failed_no_hit': 0.12267142290923504, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 53.72, 'test/accuracy_QuestionType_one': 50.73, 'test/accuracy_QuestionType_eight': 51.28, 'test/accuracy_QuestionType_other': 56.03, 'test/accuracy_QuestionType_seven': 51.5, 'test/accuracy_QuestionType_four': 61.52, 'test/accuracy_QuestionType_five': 55.08, 'test/accuracy_QuestionType_three': 53.83, 'test/accuracy_QuestionType_nine': 43.57, 'test/accuracy_QuestionType_ten': 50.08, 'test/accuracy_QuestionType_two': 55.81, 'test/accuracy_QuestionType_six': 49.93, 'test/accuracy_AnswerType_other': 53.72, 'test/epoch': 4}[0m
Epoch 4, global step 1410: 'test/accuracy_overall' reached 53.72000 (best 53.72000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249/train/saved_model/model_4.ckpt' as top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5921521997621879, 'test/exact_match_at_2': 0.7009512485136742, 'test/exact_match_at_3': 0.7302814110186286, 'test/exact_match_at_4': 0.7368212445501388, 'test/exact_match_at_5': 0.7374157748711851, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.363337296868807, 'test/successful_no_hit': 0.1917162108600872, 'test/failed_hit': 0.2378913991280222, 'test/failed_no_hit': 0.20705509314308362, 'test/selected_successful_hit': 0.43638525564803804, 'test/selected_successful_no_hit': 0.15576694411414982, 'test/selected_failed_hit': 0.26595323028141105, 'test/selected_failed_no_hit': 0.14189456995640112, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 54.21, 'test/accuracy_QuestionType_one': 49.79, 'test/accuracy_QuestionType_eight': 52.35, 'test/accuracy_QuestionType_other': 54.96, 'test/accuracy_QuestionType_seven': 52.9, 'test/accuracy_QuestionType_four': 62.15, 'test/accuracy_QuestionType_five': 56.52, 'test/accuracy_QuestionType_three': 54.81, 'test/accuracy_QuestionType_nine': 46.67, 'test/accuracy_QuestionType_ten': 50.54, 'test/accuracy_QuestionType_two': 56.16, 'test/accuracy_QuestionType_six': 50.21, 'test/accuracy_AnswerType_other': 54.21, 'test/epoch': 5}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5887831946095917, 'test/exact_match_at_2': 0.7019421323820848, 'test/exact_match_at_3': 0.7318668252080857, 'test/exact_match_at_4': 0.7405866032500991, 'test/exact_match_at_5': 0.7429647245342846, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.36753864447086804, 'test/successful_no_hit': 0.18410622275069363, 'test/failed_hit': 0.25005945303210464, 'test/failed_no_hit': 0.19829567974633372, 'test/selected_successful_hit': 0.43717796274276655, 'test/selected_successful_no_hit': 0.1516052318668252, 'test/selected_failed_hit': 0.28180737217598095, 'test/selected_failed_no_hit': 0.12940943321442727, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 54.03, 'test/accuracy_QuestionType_one': 50.77, 'test/accuracy_QuestionType_eight': 51.4, 'test/accuracy_QuestionType_other': 55.64, 'test/accuracy_QuestionType_seven': 52.94, 'test/accuracy_QuestionType_four': 62.65, 'test/accuracy_QuestionType_five': 55.45, 'test/accuracy_QuestionType_three': 54.16, 'test/accuracy_QuestionType_nine': 43.33, 'test/accuracy_QuestionType_ten': 51.78, 'test/accuracy_QuestionType_two': 54.77, 'test/accuracy_QuestionType_six': 49.5, 'test/accuracy_AnswerType_other': 54.03, 'test/epoch': 5}[0m
Epoch 5, global step 1692: 'test/accuracy_overall' reached 54.03000 (best 54.03000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249/train/saved_model/model_5.ckpt' as top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5885850178359097, 'test/exact_match_at_2': 0.6995640110978993, 'test/exact_match_at_3': 0.7302814110186286, 'test/exact_match_at_4': 0.7384066587395958, 'test/exact_match_at_5': 0.7393975426080064, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.36555687673404674, 'test/successful_no_hit': 0.18430439952437574, 'test/failed_hit': 0.24597701149425288, 'test/failed_no_hit': 0.2041617122473246, 'test/selected_successful_hit': 0.43896155370590567, 'test/selected_successful_no_hit': 0.14962346413000396, 'test/selected_failed_hit': 0.2744748315497424, 'test/selected_failed_no_hit': 0.136940150614348, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 54.0, 'test/accuracy_QuestionType_one': 49.99, 'test/accuracy_QuestionType_eight': 51.84, 'test/accuracy_QuestionType_other': 55.54, 'test/accuracy_QuestionType_seven': 53.22, 'test/accuracy_QuestionType_four': 61.98, 'test/accuracy_QuestionType_five': 56.07, 'test/accuracy_QuestionType_three': 53.04, 'test/accuracy_QuestionType_nine': 44.05, 'test/accuracy_QuestionType_ten': 51.16, 'test/accuracy_QuestionType_two': 55.93, 'test/accuracy_QuestionType_six': 50.92, 'test/accuracy_AnswerType_other': 54.0, 'test/epoch': 6}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5905667855727309, 'test/exact_match_at_2': 0.7013476020610384, 'test/exact_match_at_3': 0.7318668252080857, 'test/exact_match_at_4': 0.739001189060642, 'test/exact_match_at_5': 0.7409829567974633, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.36535869996036463, 'test/successful_no_hit': 0.18771304003170827, 'test/failed_hit': 0.24534284581847007, 'test/failed_no_hit': 0.201585414189457, 'test/selected_successful_hit': 0.43737613951644866, 'test/selected_successful_no_hit': 0.15319064605628221, 'test/selected_failed_hit': 0.27625842251288146, 'test/selected_failed_no_hit': 0.13317479191438764, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 54.13, 'test/accuracy_QuestionType_one': 50.68, 'test/accuracy_QuestionType_eight': 52.37, 'test/accuracy_QuestionType_other': 55.67, 'test/accuracy_QuestionType_seven': 53.69, 'test/accuracy_QuestionType_four': 61.48, 'test/accuracy_QuestionType_five': 55.6, 'test/accuracy_QuestionType_three': 52.99, 'test/accuracy_QuestionType_nine': 44.05, 'test/accuracy_QuestionType_ten': 52.09, 'test/accuracy_QuestionType_two': 56.05, 'test/accuracy_QuestionType_six': 50.35, 'test/accuracy_AnswerType_other': 54.13, 'test/epoch': 6}[0m
Epoch 6, global step 1974: 'test/accuracy_overall' reached 54.13000 (best 54.13000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249/train/saved_model/model_6.ckpt' as top 1
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5899722552516845, 'test/exact_match_at_2': 0.7013476020610384, 'test/exact_match_at_3': 0.7334522393975426, 'test/exact_match_at_4': 0.7401902497027348, 'test/exact_match_at_5': 0.7427665477606025, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.3658739595719382, 'test/successful_no_hit': 0.1881886642885454, 'test/failed_hit': 0.244867221561633, 'test/failed_no_hit': 0.20107015457788346, 'test/selected_successful_hit': 0.4359889021006738, 'test/selected_successful_no_hit': 0.1539833531510107, 'test/selected_failed_hit': 0.2744748315497424, 'test/selected_failed_no_hit': 0.13555291319857313, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 54.13, 'test/accuracy_QuestionType_one': 50.43, 'test/accuracy_QuestionType_eight': 51.7, 'test/accuracy_QuestionType_other': 55.44, 'test/accuracy_QuestionType_seven': 53.64, 'test/accuracy_QuestionType_four': 62.29, 'test/accuracy_QuestionType_five': 56.67, 'test/accuracy_QuestionType_three': 52.8, 'test/accuracy_QuestionType_nine': 42.86, 'test/accuracy_QuestionType_ten': 49.77, 'test/accuracy_QuestionType_two': 55.93, 'test/accuracy_QuestionType_six': 51.35, 'test/accuracy_AnswerType_other': 54.13, 'test/epoch': 7}[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_exact_match'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_retrieval_metrics'}...[0m
[38;20m[INFO] - trainers.metrics_processors : Running metrics {'name': 'compute_okvqa_scores'}...[0m
[38;20m[INFO] - trainers.rag_executor : Evaluation results [validate]: {'test/exact_match_at_1': 0.5901704320253667, 'test/exact_match_at_2': 0.6999603646452636, 'test/exact_match_at_3': 0.7320650019817677, 'test/exact_match_at_4': 0.7386048355132778, 'test/exact_match_at_5': 0.7407847800237812, 'test/recall_at_5': 0.8127229488703924, 'test/precision_at_5': 0.5183511692429646, 'test/gold_precision_at_5': 0.37237415774871185, 'test/gold_recall_at_5': 0.665477606024574, 'test/successful_hit': 0.3644470868014269, 'test/successful_no_hit': 0.1904478795085216, 'test/failed_hit': 0.24165675782798257, 'test/failed_no_hit': 0.20344827586206896, 'test/selected_successful_hit': 0.4342053111375347, 'test/selected_successful_no_hit': 0.15596512088783196, 'test/selected_failed_hit': 0.27170035671819265, 'test/selected_failed_no_hit': 0.13812921125644073, 'test/n_retrieved_docs': 5, 'test/accuracy_overall': 54.17, 'test/accuracy_QuestionType_one': 50.87, 'test/accuracy_QuestionType_eight': 51.74, 'test/accuracy_QuestionType_other': 55.35, 'test/accuracy_QuestionType_seven': 53.08, 'test/accuracy_QuestionType_four': 62.43, 'test/accuracy_QuestionType_five': 56.35, 'test/accuracy_QuestionType_three': 53.41, 'test/accuracy_QuestionType_nine': 42.86, 'test/accuracy_QuestionType_ten': 51.01, 'test/accuracy_QuestionType_two': 55.58, 'test/accuracy_QuestionType_six': 50.64, 'test/accuracy_AnswerType_other': 54.17, 'test/epoch': 7}[0m
Epoch 7, global step 2256: 'test/accuracy_overall' reached 54.17000 (best 54.17000), saving model to '/rds/user/xl544/hpc-work/Retrieval-Augmented-Visual-Question-Answering/Experiments/OKVQA_RA-VQA-T5-qformer-flan.21921249/train/saved_model/model_7.ckpt' as top 1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                                     epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:            test/accuracy_AnswerType_other ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   test/accuracy_AnswerType_other_auto_max ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   test/accuracy_AnswerType_other_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          test/accuracy_QuestionType_eight ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá
wandb: test/accuracy_QuestionType_eight_auto_max ‚ñÅ‚ñÑ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: test/accuracy_QuestionType_eight_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           test/accuracy_QuestionType_five ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:  test/accuracy_QuestionType_five_auto_max ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà
wandb:  test/accuracy_QuestionType_five_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           test/accuracy_QuestionType_four ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà
wandb:  test/accuracy_QuestionType_four_auto_max ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  test/accuracy_QuestionType_four_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           test/accuracy_QuestionType_nine ‚ñÉ‚ñÑ‚ñÅ‚ñÖ‚ñá‚ñá‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ
wandb:  test/accuracy_QuestionType_nine_auto_max ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà
wandb:  test/accuracy_QuestionType_nine_auto_min ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            test/accuracy_QuestionType_one ‚ñÅ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà
wandb:   test/accuracy_QuestionType_one_auto_max ‚ñÅ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:   test/accuracy_QuestionType_one_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          test/accuracy_QuestionType_other ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá
wandb: test/accuracy_QuestionType_other_auto_max ‚ñÅ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: test/accuracy_QuestionType_other_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          test/accuracy_QuestionType_seven ‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñÜ
wandb: test/accuracy_QuestionType_seven_auto_max ‚ñÅ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb: test/accuracy_QuestionType_seven_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            test/accuracy_QuestionType_six ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñà‚ñá
wandb:   test/accuracy_QuestionType_six_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb:   test/accuracy_QuestionType_six_auto_min ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            test/accuracy_QuestionType_ten ‚ñÅ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÜ
wandb:   test/accuracy_QuestionType_ten_auto_max ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   test/accuracy_QuestionType_ten_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          test/accuracy_QuestionType_three ‚ñÅ‚ñÉ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá
wandb: test/accuracy_QuestionType_three_auto_max ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñà‚ñà‚ñà
wandb: test/accuracy_QuestionType_three_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            test/accuracy_QuestionType_two ‚ñà‚ñÖ‚ñÑ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñá
wandb:   test/accuracy_QuestionType_two_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñà‚ñà‚ñà
wandb:   test/accuracy_QuestionType_two_auto_min ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                     test/accuracy_overall ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:            test/accuracy_overall_auto_max ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:            test/accuracy_overall_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                test/epoch ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà
wandb:                       test/epoch_auto_max ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñà
wandb:                       test/epoch_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                     test/exact_match_at_1 ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:            test/exact_match_at_1_auto_max ‚ñÅ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:            test/exact_match_at_1_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                     test/exact_match_at_2 ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:            test/exact_match_at_2_auto_max ‚ñÅ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:            test/exact_match_at_2_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                     test/exact_match_at_3 ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:            test/exact_match_at_3_auto_max ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:            test/exact_match_at_3_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                     test/exact_match_at_4 ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:            test/exact_match_at_4_auto_max ‚ñÅ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:            test/exact_match_at_4_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                     test/exact_match_at_5 ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá
wandb:            test/exact_match_at_5_auto_max ‚ñÅ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:            test/exact_match_at_5_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                           test/failed_hit ‚ñá‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                  test/failed_hit_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  test/failed_hit_auto_min ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                        test/failed_no_hit ‚ñÖ‚ñÅ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá
wandb:               test/failed_no_hit_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÜ‚ñà‚ñà‚ñà
wandb:               test/failed_no_hit_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  test/gold_precision_at_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:         test/gold_precision_at_5_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:         test/gold_precision_at_5_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                     test/gold_recall_at_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            test/gold_recall_at_5_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            test/gold_recall_at_5_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                     test/n_retrieved_docs ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            test/n_retrieved_docs_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            test/n_retrieved_docs_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       test/precision_at_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:              test/precision_at_5_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:              test/precision_at_5_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                          test/recall_at_5 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 test/recall_at_5_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 test/recall_at_5_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  test/selected_failed_hit ‚ñà‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:         test/selected_failed_hit_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:         test/selected_failed_hit_auto_min ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:               test/selected_failed_no_hit ‚ñÑ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñà
wandb:      test/selected_failed_no_hit_auto_max ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñà‚ñà‚ñà
wandb:      test/selected_failed_no_hit_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:              test/selected_successful_hit ‚ñÅ‚ñá‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñÜ
wandb:     test/selected_successful_hit_auto_max ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:     test/selected_successful_hit_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           test/selected_successful_no_hit ‚ñÇ‚ñÅ‚ñÑ‚ñÉ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  test/selected_successful_no_hit_auto_max ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb:  test/selected_successful_no_hit_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       test/successful_hit ‚ñÅ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:              test/successful_hit_auto_max ‚ñÅ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:              test/successful_hit_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                    test/successful_no_hit ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:           test/successful_no_hit_auto_max ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà
wandb:           test/successful_no_hit_auto_min ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                          train/loss_epoch ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                 train/loss_epoch_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 train/loss_epoch_auto_min ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:                           train/loss_step ‚ñà‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ
wandb:                  train/loss_step_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  train/loss_step_auto_min ‚ñà‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                               train/lr[0] ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                      train/lr[0]_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                      train/lr[0]_auto_min ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb:                               train/lr[1] ‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:                      train/lr[1]_auto_max ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                      train/lr[1]_auto_min ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb:                       trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: 
wandb: Run summary:
wandb:                                     epoch 7
wandb:            test/accuracy_AnswerType_other 54.17
wandb:   test/accuracy_AnswerType_other_auto_max 54.21
wandb:   test/accuracy_AnswerType_other_auto_min 48.14
wandb:          test/accuracy_QuestionType_eight 51.74
wandb: test/accuracy_QuestionType_eight_auto_max 52.37
wandb: test/accuracy_QuestionType_eight_auto_min 46.6
wandb:           test/accuracy_QuestionType_five 56.35
wandb:  test/accuracy_QuestionType_five_auto_max 56.67
wandb:  test/accuracy_QuestionType_five_auto_min 48.57
wandb:           test/accuracy_QuestionType_four 62.43
wandb:  test/accuracy_QuestionType_four_auto_max 62.65
wandb:  test/accuracy_QuestionType_four_auto_min 54.53
wandb:           test/accuracy_QuestionType_nine 42.86
wandb:  test/accuracy_QuestionType_nine_auto_max 46.67
wandb:  test/accuracy_QuestionType_nine_auto_min 38.57
wandb:            test/accuracy_QuestionType_one 50.87
wandb:   test/accuracy_QuestionType_one_auto_max 50.87
wandb:   test/accuracy_QuestionType_one_auto_min 43.15
wandb:          test/accuracy_QuestionType_other 55.35
wandb: test/accuracy_QuestionType_other_auto_max 56.03
wandb: test/accuracy_QuestionType_other_auto_min 49.31
wandb:          test/accuracy_QuestionType_seven 53.08
wandb: test/accuracy_QuestionType_seven_auto_max 54.21
wandb: test/accuracy_QuestionType_seven_auto_min 49.49
wandb:            test/accuracy_QuestionType_six 50.64
wandb:   test/accuracy_QuestionType_six_auto_max 51.35
wandb:   test/accuracy_QuestionType_six_auto_min 46.67
wandb:            test/accuracy_QuestionType_ten 51.01
wandb:   test/accuracy_QuestionType_ten_auto_max 53.64
wandb:   test/accuracy_QuestionType_ten_auto_min 46.2
wandb:          test/accuracy_QuestionType_three 53.41
wandb: test/accuracy_QuestionType_three_auto_max 54.81
wandb: test/accuracy_QuestionType_three_auto_min 47.06
wandb:            test/accuracy_QuestionType_two 55.58
wandb:   test/accuracy_QuestionType_two_auto_max 56.16
wandb:   test/accuracy_QuestionType_two_auto_min 50.47
wandb:                     test/accuracy_overall 54.17
wandb:            test/accuracy_overall_auto_max 54.21
wandb:            test/accuracy_overall_auto_min 48.14
wandb:                                test/epoch 7.0
wandb:                       test/epoch_auto_max 7.0
wandb:                       test/epoch_auto_min 0.0
wandb:                     test/exact_match_at_1 0.59017
wandb:            test/exact_match_at_1_auto_max 0.59215
wandb:            test/exact_match_at_1_auto_min 0.52398
wandb:                     test/exact_match_at_2 0.69996
wandb:            test/exact_match_at_2_auto_max 0.70373
wandb:            test/exact_match_at_2_auto_min 0.64427
wandb:                     test/exact_match_at_3 0.73207
wandb:            test/exact_match_at_3_auto_max 0.73841
wandb:            test/exact_match_at_3_auto_min 0.68629
wandb:                     test/exact_match_at_4 0.7386
wandb:            test/exact_match_at_4_auto_max 0.74772
wandb:            test/exact_match_at_4_auto_min 0.70055
wandb:                     test/exact_match_at_5 0.74078
wandb:            test/exact_match_at_5_auto_max 0.7495
wandb:            test/exact_match_at_5_auto_min 0.70333
wandb:                           test/failed_hit 0.24166
wandb:                  test/failed_hit_auto_max 0.34538
wandb:                  test/failed_hit_auto_min 0.23789
wandb:                        test/failed_no_hit 0.20345
wandb:               test/failed_no_hit_auto_max 0.20706
wandb:               test/failed_no_hit_auto_min 0.16461
wandb:                  test/gold_precision_at_5 0.37237
wandb:         test/gold_precision_at_5_auto_max 0.37237
wandb:         test/gold_precision_at_5_auto_min 0.37237
wandb:                     test/gold_recall_at_5 0.66548
wandb:            test/gold_recall_at_5_auto_max 0.66548
wandb:            test/gold_recall_at_5_auto_min 0.66548
wandb:                     test/n_retrieved_docs 5.0
wandb:            test/n_retrieved_docs_auto_max 5.0
wandb:            test/n_retrieved_docs_auto_min 5.0
wandb:                       test/precision_at_5 0.51835
wandb:              test/precision_at_5_auto_max 0.51835
wandb:              test/precision_at_5_auto_min 0.51835
wandb:                          test/recall_at_5 0.81272
wandb:                 test/recall_at_5_auto_max 0.81272
wandb:                 test/recall_at_5_auto_min 0.81272
wandb:                  test/selected_failed_hit 0.2717
wandb:         test/selected_failed_hit_auto_max 0.37158
wandb:         test/selected_failed_hit_auto_min 0.26595
wandb:               test/selected_failed_no_hit 0.13813
wandb:      test/selected_failed_no_hit_auto_max 0.14189
wandb:      test/selected_failed_no_hit_auto_min 0.0874
wandb:              test/selected_successful_hit 0.43421
wandb:     test/selected_successful_hit_auto_max 0.44273
wandb:     test/selected_successful_hit_auto_min 0.41379
wandb:           test/selected_successful_no_hit 0.15597
wandb:  test/selected_successful_no_hit_auto_max 0.15597
wandb:  test/selected_successful_no_hit_auto_min 0.10226
wandb:                       test/successful_hit 0.36445
wandb:              test/successful_hit_auto_max 0.3698
wandb:              test/successful_hit_auto_min 0.34094
wandb:                    test/successful_no_hit 0.19045
wandb:           test/successful_no_hit_auto_max 0.19172
wandb:           test/successful_no_hit_auto_min 0.13436
wandb:                          train/loss_epoch 0.44236
wandb:                 train/loss_epoch_auto_max 1.44034
wandb:                 train/loss_epoch_auto_min 0.46477
wandb:                           train/loss_step 0.36444
wandb:                  train/loss_step_auto_max 2.61865
wandb:                  train/loss_step_auto_min 0.00671
wandb:                               train/lr[0] 0.0
wandb:                      train/lr[0]_auto_max 6e-05
wandb:                      train/lr[0]_auto_min 0.0
wandb:                               train/lr[1] 0.0
wandb:                      train/lr[1]_auto_max 1e-05
wandb:                      train/lr[1]_auto_min 0.0
wandb:                       trainer/global_step 2255
wandb: 
wandb: üöÄ View run OKVQA_RA-VQA-T5-qformer-flan.21921249 at: https://wandb.ai/xl544/RAVQA/runs/is6hfjv8
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230609_014946-is6hfjv8/logs
